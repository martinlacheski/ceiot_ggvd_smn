{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57602088",
   "metadata": {},
   "source": [
    "# Clasificación de datos – SMN\n",
    "\n",
    "En esta sección aplicaremos **métodos de clasificación** utilizando los datos meteorológicos\n",
    "procesados en la **Capa Minería de Datos**, para predecir si **llueve o no llueve** en base a variables como:\n",
    "\n",
    "- Temperatura (`TEMP`)\n",
    "- Humedad (`HUM`)\n",
    "- Presión (`PNM`)\n",
    "- Dirección del viento (`DD`)\n",
    "- Velocidad del viento (`FF`)\n",
    "\n",
    "Se utilizarán tres algoritmos de clasificación:\n",
    "\n",
    "1. Árbol de Decisión\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Regresión Logística\n",
    "\n",
    "Se evaluarán con métricas clásicas:\n",
    "\n",
    "- **Accuracy**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-Score**\n",
    "\n",
    "Y visualizaremos **matrices de confusión** para interpretar los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b396b85-50af-448d-a4ba-42e441067f6a",
   "metadata": {},
   "source": [
    "# Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54badf77-28f5-43e1-bae3-c299b1068159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "CLASIFICACION_DIR = Path('../data/clasificacion')\n",
    "CLASIFICACION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Importación de librerías completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3da64f",
   "metadata": {},
   "source": [
    "# Carga de datos y selección de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5328cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar el dataset horario\n",
    "df = pd.read_csv(\"../data/mineria/dataset_mineria_horario.csv\")\n",
    "\n",
    "# Variables predictoras y objetivo\n",
    "X = df[['TEMP', 'HUM', 'PNM', 'DD', 'FF']]\n",
    "y = df['LLUEVE']\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb94fcb",
   "metadata": {},
   "source": [
    "# División en conjuntos de entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cef93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Dimensiones de los conjuntos de datos:\")\n",
    "print(f\"  X_train: {X_train.shape} -> {X_train.shape[0]} filas, {X_train.shape[1]} variables predictoras\")\n",
    "print(f\"  X_test : {X_test.shape} -> {X_test.shape[0]} filas, {X_test.shape[1]} variables predictoras\")\n",
    "print(f\"  y_train: {y_train.shape[0]} filas\")\n",
    "print(f\"  y_test : {y_test.shape[0]} filas\")\n",
    "\n",
    "print(\"\\nDistribución de clases en entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución de clases en prueba:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d0269",
   "metadata": {},
   "source": [
    "# Estandarización de variables\n",
    "Para KNN y regresión logística es importante escalar las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y ajustar el escalador\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Mostrar información interpretativa\n",
    "print(\"=== Estandarización de variables ===\")\n",
    "print(\"Antes de escalar (primeras 5 filas):\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nDespués de escalar (primeras 5 filas):\")\n",
    "print(pd.DataFrame(X_train_scaled, columns=X_train.columns).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146387c7",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06870508",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Entrenamiento de Modelos de Clasificación ===\\n\")\n",
    "\n",
    "# Árbol de Decisión - No necesita estandarización porque no depende de la magnitud de las variables.\n",
    "model_tree = DecisionTreeClassifier(random_state=42)\n",
    "model_tree.fit(X_train, y_train)\n",
    "print(\"Modelo Árbol de Decisión entrenado.\")\n",
    "print(f\"Profundidad del árbol: {model_tree.get_depth()}\")\n",
    "print(f\"Número de hojas: {model_tree.get_n_leaves()}\\n\")\n",
    "\n",
    "# K-Nearest Neighbors (KNN) - Necesita variables escaladas para que la distancia euclidiana sea representativa.\n",
    "neighbors = 5\n",
    "model_knn = KNeighborsClassifier(n_neighbors= neighbors)\n",
    "model_knn.fit(X_train_scaled, y_train)\n",
    "print(\"Modelo KNN entrenado (con datos estandarizados).\")\n",
    "print(f\"Número de vecinos usados: {model_knn.n_neighbors}\")\n",
    "print(f\"Forma de los datos entrenados: {model_knn._fit_X.shape}\\n\")\n",
    "\n",
    "# Regresión Logística - También requiere estandarización para mejorar la convergencia del algoritmo.\n",
    "model_log = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_log.fit(X_train_scaled, y_train)\n",
    "print(\"Modelo de Regresión Logística entrenado (con datos estandarizados).\")\n",
    "print(\"Coeficientes por variable (impacto en la probabilidad de lluvia):\")\n",
    "for var, coef in zip(X_train.columns, model_log.coef_[0]):\n",
    "    print(f\"  {var}: {coef:.4f}\")\n",
    "print(f\"Intersección (bias): {model_log.intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9474f7-7317-4c6b-b77c-5c8584d74374",
   "metadata": {},
   "source": [
    "## Interpretación del Entrenamiento de Modelos\n",
    "\n",
    "Luego de entrenar los tres modelos de clasificación, obtenemos información sobre su estructura y parámetros:\n",
    "\n",
    "### Árbol de Decisión\n",
    "- **Profundidad**: Indica cuántas divisiones jerárquicas se realizaron.\n",
    "- **Número de hojas**: Cada hoja representa una **clase final** (llueve / no llueve).\n",
    "\n",
    "En el ejemplo:\n",
    "- Profundidad: `2` → Árbol muy simple, fácil de interpretar.\n",
    "- Hojas: `3` → Tres rutas posibles de decisión.\n",
    "\n",
    "> **Interpretación:**  \n",
    "Un árbol con baja profundidad es más interpretable, pero puede perder precisión si el fenómeno es complejo.  \n",
    "Se busca un equilibrio entre simplicidad y desempeño.\n",
    "\n",
    "---\n",
    "\n",
    "### K-Nearest Neighbors (KNN)\n",
    "- **Número de vecinos usados**: `5`  \n",
    "- **Forma de los datos entrenados**: `(14101, 5)`  \n",
    "\n",
    "Esto significa:\n",
    "- El modelo **almacena todo el conjunto de entrenamiento** para calcular distancias.  \n",
    "- Usa **5 vecinos más cercanos** para decidir si llueve o no.  \n",
    "- Cada fila tiene **5 variables predictoras**: `TEMP`, `HUM`, `PNM`, `DD`, `FF`.\n",
    "\n",
    "> **Interpretación:**  \n",
    "KNN es un modelo **basado en similitud**.  \n",
    "No aprende reglas explícitas, sino que **compara nuevas observaciones** con las ya conocidas.\n",
    "\n",
    "---\n",
    "\n",
    "### Regresión Logística\n",
    "Imprime los **coeficientes de cada variable** y el **intercepto (bias)**.\n",
    "\n",
    "- **Coeficientes**: Indican cómo cambia la **probabilidad de lluvia** según cada variable:  \n",
    "  - Positivo → aumenta la probabilidad de lluvia  \n",
    "  - Negativo → disminuye la probabilidad de lluvia  \n",
    "\n",
    "Ejemplo interpretativo:\n",
    "- `HUM` positivo → mayor humedad favorece la lluvia.\n",
    "- `PNM` negativo → baja presión favorece la lluvia.\n",
    "- `TEMP` negativo → temperaturas altas reducen la probabilidad de lluvia.\n",
    "\n",
    "- **Intercepto (bias)**: `-7.0516`  \n",
    "  - Representa la **tendencia base** del modelo cuando todas las variables están en sus valores promedio (tras la estandarización).  \n",
    "  - Es un **log-odds**, que se puede convertir en probabilidad:  \n",
    "\n",
    "\\[\n",
    "p = \\frac{1}{1 + e^{-(-7.0516)}} \\approx 0.00086\n",
    "\\]\n",
    "\n",
    "Esto significa que **la probabilidad de lluvia base es muy baja**, y solo aumentará si las variables lo justifican (humedad alta y presión baja).\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen\n",
    "- **Árbol de Decisión**: genera reglas explícitas y es interpretable.  \n",
    "- **KNN**: no genera reglas, clasifica por similitud con vecinos cercanos.  \n",
    "- **Regresión Logística**: asigna un **peso** a cada variable y una probabilidad de lluvia.  \n",
    "- El **bias negativo** indica que el modelo, sin señales claras, tiende a predecir **“no llueve”**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c774c",
   "metadata": {},
   "source": [
    "# Evaluación de modelos\n",
    "Se usarán **accuracy, precision, recall y F1-score**, junto con la **matriz de confusión** para visualizar los aciertos y errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar un modelo mostrando métricas y matriz de confusión.\n",
    "def evaluar_modelo(nombre, modelo, X_eval, y_eval):\n",
    "    \n",
    "    y_pred = modelo.predict(X_eval)\n",
    "\n",
    "    # === Métricas ===\n",
    "    acc = accuracy_score(y_eval, y_pred)\n",
    "    prec = precision_score(y_eval, y_pred)\n",
    "    rec = recall_score(y_eval, y_pred)\n",
    "    f1 = f1_score(y_eval, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {nombre} ===\")\n",
    "    print(f\"Accuracy : {acc:.3f} -> Proporción total de aciertos\")\n",
    "    print(f\"Precision: {prec:.3f} -> De los 'llueve' predichos, cuántos fueron correctos\")\n",
    "    print(f\"Recall   : {rec:.3f} -> De las lluvias reales, cuántas detectó el modelo\")\n",
    "    print(f\"F1-Score : {f1:.3f} -> Balance entre Precision y Recall\")\n",
    "\n",
    "    # === Matriz de Confusión ===\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                     xticklabels=[\"No Llueve\",\"Llueve\"], \n",
    "                     yticklabels=[\"No Llueve\",\"Llueve\"])\n",
    "\n",
    "    # Cambiar color de texto según el valor\n",
    "    max_val = cm.max()\n",
    "    for text in ax.texts:\n",
    "        val = int(text.get_text())\n",
    "        # Blanco si valor alto, negro si valor bajo\n",
    "        text.set_color(\"white\" if val > max_val/2 else \"black\")\n",
    "        text.set_size(16)\n",
    "        text.set_weight('bold')\n",
    "\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(f\"Matriz de Confusión - {nombre}\")\n",
    "    plt.show()\n",
    "\n",
    "    return [acc, prec, rec, f1]\n",
    "\n",
    "# Evaluación de los tres modelos\n",
    "resultados = []\n",
    "resultados.append(evaluar_modelo(\"Árbol de Decisión\", model_tree, X_test, y_test))\n",
    "resultados.append(evaluar_modelo(\"KNN\", model_knn, X_test_scaled, y_test))\n",
    "resultados.append(evaluar_modelo(\"Regresión Logística\", model_log, X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b2fbc",
   "metadata": {},
   "source": [
    "## Comparativa de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados, columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"],\n",
    "                             index=[\"Árbol de Decisión\",\"KNN\",\"Regresión Logística\"])\n",
    "df_resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b14a6",
   "metadata": {},
   "source": [
    "## Cierre de comparativa de métricas\n",
    "\n",
    "- El modelo con mayor **accuracy** indica la mejor capacidad de predicción global.\n",
    "- La **precisión** muestra cuántos de los eventos predichos como lluvia fueron correctos.\n",
    "- El **recall** indica cuántas lluvias reales fueron detectadas.\n",
    "- El **F1-score** balancea precisión y recall, útil si las clases están desbalanceadas.\n",
    "\n",
    "**Interpretación típica:**\n",
    "- Si KNN tiene buen F1-score pero bajo accuracy, es sensible al desbalance.\n",
    "- Si Árbol de Decisión obtiene buen accuracy pero menor recall, puede estar subestimando lluvias.\n",
    "- La elección final depende de priorizar **detectar lluvias** (recall) o **evitar falsas alarmas** (precision).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107793e9-d9b8-4cd0-b99f-b432aa525466",
   "metadata": {},
   "source": [
    "# Guardar el dataset con las predicciones realizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68ca16-6caf-429c-bf8d-a0afd4b3a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar DataFrame con predicciones y probabilidades\n",
    "df_predicciones = df.loc[y_test.index, [\"NOMBRE\",\"FECHA_HORA\",\"LLUEVE\"]].copy()\n",
    "\n",
    "# Predicciones\n",
    "df_predicciones[\"tree_pred\"] = model_tree.predict(X_test)\n",
    "df_predicciones[\"knn_pred\"] = model_knn.predict(X_test_scaled)\n",
    "df_predicciones[\"log_pred\"] = model_log.predict(X_test_scaled)\n",
    "\n",
    "# Probabilidades de lluvia\n",
    "df_predicciones[\"knn_proba\"] = model_knn.predict_proba(X_test_scaled)[:,1]\n",
    "df_predicciones[\"log_proba\"] = model_log.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Crear DataFrame de métricas comparativas\n",
    "df_metricas = pd.DataFrame(resultados, \n",
    "                           columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"],\n",
    "                           index=[\"Árbol de Decisión\",\"KNN\",\"Regresión Logística\"])\n",
    "\n",
    "# Guardar como CSV\n",
    "\n",
    "# Guardar los datasets con las predicciones realizadas. Exportación a CSV\n",
    "df_predicciones.to_csv(CLASIFICACION_DIR / 'clasificacion_predicciones.csv', index=False)\n",
    "print(\"Archivo 'clasificacion_predicciones.csv' generado correctamente.\")\n",
    "\n",
    "# Guardar como CSV\n",
    "df_metricas.to_csv(CLASIFICACION_DIR / 'clasificacion_metricas.csv', index=False)\n",
    "print(\"Archivo 'clasificacion_metricas.csv' generado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6bda5-cf73-4f56-b7ed-3d37a5a571c9",
   "metadata": {},
   "source": [
    "# Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e980cc7-9cb0-4d8b-b3a8-9801329cb1aa",
   "metadata": {},
   "source": [
    "## Curva ROC y AUC\n",
    "\n",
    "La **Curva ROC (Receiver Operating Characteristic)** muestra la capacidad del modelo para distinguir entre clases.\n",
    "- **Eje X**: Falsos positivos (1 - Especificidad)\n",
    "- **Eje Y**: Verdaderos positivos (Recall o Sensibilidad)\n",
    "- **AUC**: Área bajo la curva; cuanto más cercano a 1, mejor el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7a426-3afd-4488-9aca-a23572c8dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con Regresión Logística\n",
    "y_proba = model_log.predict_proba(X_test_scaled)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC={auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel(\"Tasa de Falsos Positivos (1 - Especificidad)\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos (Recall)\")\n",
    "plt.title(\"Curva ROC - Regresión Logística\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6c2d3-d5b1-488f-9f27-e5b0073fc4bd",
   "metadata": {},
   "source": [
    "## Importancia de Variables (Árbol de Decisión)\n",
    "\n",
    "El **Árbol de Decisión** permite visualizar qué variables tuvieron más influencia para predecir si llueve o no.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d5054-9a97-43e6-a2c7-c88f726d26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = pd.Series(model_tree.feature_importances_, index=X_train.columns)\n",
    "importancia.sort_values().plot(kind='barh', figsize=(6,4), color='skyblue')\n",
    "plt.title(\"Importancia de variables - Árbol de Decisión\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32040821-f73a-438e-8ae9-021c21da0474",
   "metadata": {},
   "source": [
    "## Matriz de Confusión Normalizada\n",
    "\n",
    "La matriz normalizada muestra la proporción de aciertos y errores por clase, facilitando la interpretación cuando hay clases desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f6ad4-a506-485c-85ea-d6edf7b04b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, model_log.predict(X_test_scaled), normalize='true')\n",
    "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=[\"No Llueve\",\"Llueve\"], yticklabels=[\"No Llueve\",\"Llueve\"])\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión Normalizada - Regresión Logística\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43049597-38bf-4426-b3a9-5a8f09c7c95f",
   "metadata": {},
   "source": [
    "## Distribución de Probabilidades Predichas\n",
    "\n",
    "La distribución de probabilidades permite ver:\n",
    "- Qué tan seguro está el modelo al predecir\n",
    "- Cómo se superponen las clases\n",
    "- Dónde está el umbral de decisión (por defecto 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f7f6e-4f9c-483e-93c5-5af4b48b0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model_log.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_proba[y_test==0], bins=30, alpha=0.6, label='No Llueve')\n",
    "plt.hist(y_proba[y_test==1], bins=30, alpha=0.6, label='Llueve')\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Umbral 0.5')\n",
    "plt.xlabel(\"Probabilidad predicha de lluvia\")\n",
    "plt.ylabel(\"Cantidad de muestras\")\n",
    "plt.title(\"Distribución de probabilidades predichas - Regresión Logística\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4128c02-45e5-4a11-9413-04cf7d9ee234",
   "metadata": {},
   "source": [
    "## Comparativa de Métricas entre Modelos\n",
    "\n",
    "Permite ver de manera clara cuál modelo tiene mejor:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51210246-85c1-4e37-97cb-e75dc1f59f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame con resultados\n",
    "df_resultados = pd.DataFrame(resultados, \n",
    "                             columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"],\n",
    "                             index=[\"Árbol de Decisión\",\"KNN\",\"Regresión Logística\"])\n",
    "\n",
    "# Crear gráfico de barras con Blues y bordes\n",
    "ax = df_resultados.plot(\n",
    "    kind='bar', figsize=(9,5), rot=0, \n",
    "    colormap='Blues', edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title(\"Comparativa de métricas por modelo\", fontsize=14)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Etiquetas dentro de las barras: blancas solo para F1-Score\n",
    "for i, container in enumerate(ax.containers):\n",
    "    # i=0 Accuracy, i=1 Precision, i=2 Recall, i=3 F1-Score\n",
    "    color_text = 'white' if i == 3 else 'black'\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='center', fontsize=8, color=color_text, weight='bold')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d4628-984b-48de-8a79-587a3b20b887",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "En esta etapa se trabajó sobre el **dataset final proveniente de la etapa de minería de datos**, donde la información ya había sido procesada y contenía la variable binaria `LLUEVE` como objetivo de clasificación.  \n",
    "El objetivo principal fue **aplicar métodos de clasificación supervisada** para predecir la ocurrencia de lluvia a partir de datos meteorológicos horarios.\n",
    "\n",
    "Se realizaron los siguientes pasos clave:\n",
    "\n",
    "1. **Selección de variables relevantes** (`TEMP`, `HUM`, `PNM`, `DD`, `FF`) como insumos para los modelos de clasificación.  \n",
    "2. **Estandarización de los datos** para algoritmos sensibles a la escala, como KNN y Regresión Logística.  \n",
    "3. **División del dataset en conjuntos de entrenamiento y prueba** para evaluar objetivamente el desempeño de los modelos.  \n",
    "4. **Entrenamiento y evaluación de modelos supervisados** (Árbol de Decisión, KNN y Regresión Logística) utilizando métricas como Accuracy, Precision, Recall y F1-Score.  \n",
    "5. **Visualizaciones complementarias** como matrices de confusión, curvas ROC, histogramas de probabilidades y análisis de importancia de variables, que permitieron interpretar los resultados y validar el desempeño de cada modelo.\n",
    "\n",
    "Este proceso consolida la etapa de **clasificación supervisada**, transformando los datos procesados en **conocimiento accionable**, y dejando una base sólida para **predicciones futuras, integración en pipelines analíticos y toma de decisiones basadas en datos**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

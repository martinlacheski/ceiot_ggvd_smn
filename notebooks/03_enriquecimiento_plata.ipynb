{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Enriquecimiento de la capa Plata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be488a-6bf7-4136-929d-7362ff0dca6c",
   "metadata": {},
   "source": [
    "En esta notebook trabajaremos sobre los datos horarios previamente generados y la capa Plata intermedia con el objetivo de **enriquecer y completar la información** antes de su uso para análisis avanzados (clustering, PCA, reglas de asociación, etc.).\n",
    "\n",
    "### Las principales tareas realizadas son:\n",
    "- Detección de fechas y horas con datos faltantes.\n",
    "- Imputación de valores `NaN` basados en el promedio del mismo horario del día anterior y posterior.\n",
    "- Comparación entre el dataset original y el imputado.\n",
    "- Exportación del dataset horario imputado.\n",
    "- Verificación final de la cobertura completa de fechas por estación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573fb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importación de librerías completada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Deshabilitar warnings futuros\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Ajustar el ancho máximo para impresión en consola\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "pd.set_option('display.width', 300)         # Ajustar a un ancho suficiente en consola\n",
    "pd.set_option('display.max_colwidth', None) # Evitar recortes en contenido de celdas\n",
    "\n",
    "print(\"Importación de librerías completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## Configuración de paths y carpetas del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069e436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciación de carpetas del proyecto completada.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "PLATA_DIR = Path(\"../data/plata\")\n",
    "\n",
    "archivo_plata = PLATA_DIR / \"dataset_plata_inicial.csv\"\n",
    "archivo_horario = PLATA_DIR / \"horario_archivo.csv\"\n",
    "\n",
    "print(\"Iniciación de carpetas del proyecto completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## Carga del dataset y verificación de estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset diario cargado correctamente\n",
      "Dataset horario cargado correctamente\n",
      "\n",
      " Dataset diario:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 844 entries, 0 to 843\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ESTACION              844 non-null    object        \n",
      " 1   FECHA                 844 non-null    datetime64[ns]\n",
      " 2   TEMP_MEAN             844 non-null    float64       \n",
      " 3   TEMP_MIN              844 non-null    float64       \n",
      " 4   TEMP_MAX              844 non-null    float64       \n",
      " 5   PNM_MEAN              844 non-null    float64       \n",
      " 6   PNM_MIN               844 non-null    float64       \n",
      " 7   PNM_MAX               844 non-null    float64       \n",
      " 8   HUM_MEAN              844 non-null    float64       \n",
      " 9   HUM_MIN               844 non-null    int64         \n",
      " 10  HUM_MAX               844 non-null    int64         \n",
      " 11  WIND_DIR_MEAN         844 non-null    float64       \n",
      " 12  WIND_DIR_MIN          844 non-null    int64         \n",
      " 13  WIND_DIR_MAX          844 non-null    int64         \n",
      " 14  WIND_SPEED_MEAN       844 non-null    float64       \n",
      " 15  WIND_SPEED_MIN        844 non-null    int64         \n",
      " 16  WIND_SPEED_MAX        844 non-null    int64         \n",
      " 17  TEMP_MEAN_NORM        844 non-null    float64       \n",
      " 18  PNM_MEAN_NORM         844 non-null    float64       \n",
      " 19  HUM_MEAN_NORM         844 non-null    float64       \n",
      " 20  WIND_DIR_MEAN_NORM    844 non-null    float64       \n",
      " 21  WIND_SPEED_MEAN_NORM  844 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(6), object(1)\n",
      "memory usage: 145.2+ KB\n",
      "\n",
      "\n",
      "        ESTACION      FECHA  TEMP_MEAN  TEMP_MIN  TEMP_MAX  PNM_MEAN  PNM_MIN  PNM_MAX  HUM_MEAN  HUM_MIN  HUM_MAX  WIND_DIR_MEAN  WIND_DIR_MIN  WIND_DIR_MAX  WIND_SPEED_MEAN  WIND_SPEED_MIN  WIND_SPEED_MAX  TEMP_MEAN_NORM  PNM_MEAN_NORM  HUM_MEAN_NORM  WIND_DIR_MEAN_NORM  WIND_SPEED_MEAN_NORM\n",
      "0  CHAPELCO AERO 2024-06-01        4.1       1.8       6.6    1014.6   1011.7   1018.1      76.4       51       93          250.0             0           290             25.5               0              39        0.204301       0.406619       0.741148            0.774326              0.611650\n",
      "1  CHAPELCO AERO 2024-06-02        1.2      -2.2       5.2    1026.2   1019.1   1030.1      83.1       57       99          100.0             0           990              9.1               0              22        0.126344       0.680851       0.822955            0.298891              0.213592\n",
      "2  CHAPELCO AERO 2024-06-03        2.8      -1.7       4.8    1020.9   1016.6   1028.9      65.5       52       94           92.9             0           270             14.0               0              22        0.169355       0.555556       0.608059            0.276387              0.332524\n",
      "3  CHAPELCO AERO 2024-06-04        4.2      -0.9      12.4    1014.5   1011.8   1017.1      84.8       63       98           52.9             0           290              2.6               0              11        0.206989       0.404255       0.843712            0.149604              0.055825\n",
      "4  CHAPELCO AERO 2024-06-05        6.9       4.6       9.2    1009.8   1008.4   1012.3      96.5       94      100          127.0             0           990              4.5               0              11        0.279570       0.293144       0.986569            0.384469              0.101942\n",
      "\n",
      " Dataset horario:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19288 entries, 0 to 19287\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   FECHA             19288 non-null  object        \n",
      " 1   HORA              19288 non-null  int64         \n",
      " 2   TEMP              19288 non-null  float64       \n",
      " 3   HUM               19288 non-null  int64         \n",
      " 4   PNM               19288 non-null  float64       \n",
      " 5   DD                19288 non-null  int64         \n",
      " 6   FF                19288 non-null  int64         \n",
      " 7   NOMBRE            19288 non-null  object        \n",
      " 8   estacion_archivo  19288 non-null  int64         \n",
      " 9   FECHA_HORA        19288 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(5), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "\n",
      "        FECHA  HORA  TEMP  HUM     PNM   DD  FF         NOMBRE  estacion_archivo          FECHA_HORA\n",
      "0  2024-11-02     0   5.8   51  1012.4  320  37  CHAPELCO AERO          20241102 2024-11-02 00:00:00\n",
      "1  2024-11-02     1   5.8   56  1013.3  300  30  CHAPELCO AERO          20241102 2024-11-02 01:00:00\n",
      "2  2024-11-02     2   5.6   58  1014.6  300  17  CHAPELCO AERO          20241102 2024-11-02 02:00:00\n",
      "3  2024-11-02     3   5.6   66  1014.1    0   0  CHAPELCO AERO          20241102 2024-11-02 03:00:00\n",
      "4  2024-11-02     4   5.4   69  1014.4  250  19  CHAPELCO AERO          20241102 2024-11-02 04:00:00\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset diario\n",
    "try:\n",
    "    df_plata = pd.read_csv(archivo_plata, parse_dates=[\"FECHA\"])\n",
    "    print(\"Dataset diario cargado correctamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo diario no fue encontrado\")\n",
    "\n",
    "# Cargar el dataset horario\n",
    "try:\n",
    "    df_horario = pd.read_csv(archivo_horario, parse_dates=[\"FECHA_HORA\"])\n",
    "    print(\"Dataset horario cargado correctamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo horario no fue encontrado\")\n",
    "\n",
    "# Vista preliminar\n",
    "print(\"\\n Dataset diario:\")\n",
    "df_plata.info()\n",
    "print(\"\\n\")\n",
    "print(df_plata.head())\n",
    "\n",
    "print(\"\\n Dataset horario:\")\n",
    "df_horario.info()\n",
    "print(\"\\n\")\n",
    "print(df_horario.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209b877-0cff-4dc7-ba04-d9ed38525d7a",
   "metadata": {},
   "source": [
    "Este paso permite validar la estructura general, tipos de datos y posibles columnas faltantes tanto en el dataset diario como en el horario. Si todo está correcto, avanzaremos con el enriquecimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## Detección y análisis de fechas faltantes\n",
    "\n",
    "Una vez verificada la estructura del dataset diario, procedemos a identificar si existen fechas faltantes en la serie por estación. \n",
    "\n",
    "Esto nos permitirá decidir estrategias para tratar los días sin registros, como imputación o exclusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392108e6-7ec0-42ce-a42f-5f1c440573fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas faltantes exportadas a: ../data/plata/fechas_faltantes.txt\n",
      "          ESTACION      FECHA\n",
      "290  CHAPELCO AERO 2024-10-24\n",
      "291   NEUQUEN AERO 2024-10-24\n",
      "372  CHAPELCO AERO 2024-12-04\n",
      "373   NEUQUEN AERO 2024-12-04\n",
      "386  CHAPELCO AERO 2024-12-11\n"
     ]
    }
   ],
   "source": [
    "# Generar el rango completo de fechas esperadas\n",
    "fechas_totales = pd.date_range(start=df_plata['FECHA'].min(), end=df_plata['FECHA'].max(), freq='D')\n",
    "\n",
    "# Obtener todas las combinaciones posibles de fecha y estación\n",
    "estaciones = df_plata['ESTACION'].unique()\n",
    "index_completo = pd.MultiIndex.from_product([fechas_totales, estaciones], names=['FECHA', 'ESTACION'])\n",
    "\n",
    "# Reindexar para insertar NaNs explícitos en las fechas faltantes\n",
    "df_plata = df_plata.set_index(['FECHA', 'ESTACION']).reindex(index_completo).reset_index()\n",
    "\n",
    "# Verificar fechas faltantes (para exportar listado)\n",
    "faltantes = df_plata[df_plata.isnull().any(axis=1)][['ESTACION', 'FECHA']]\n",
    "\n",
    "if not faltantes.empty:\n",
    "    faltantes.to_csv(PLATA_DIR / \"fechas_faltantes.txt\", index=False, sep='\\t')\n",
    "    print(\"Fechas faltantes exportadas a:\", PLATA_DIR / \"fechas_faltantes.txt\")\n",
    "else:\n",
    "    print(\"No se encontraron fechas faltantes\")\n",
    "\n",
    "# Mostrar ejemplo si hay faltantes\n",
    "print(faltantes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b85704-5591-470e-a46e-a43346980116",
   "metadata": {},
   "source": [
    "Esta estrategia asegura que cada estación tenga una fila para cada fecha del rango, incluso si originalmente no había registros ese día. Esto deja los valores faltantes como `NaN`, que luego se tratarán."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c913c6-b13f-416a-8d06-ce3e48fc53dc",
   "metadata": {},
   "source": [
    "## Tratamiento de valores nulos\n",
    "\n",
    "Luego de verificar fechas faltantes, analizamos los valores `NaN` dentro del dataset actual para decidir estrategias de imputación o tratamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f65cc-3a3a-4170-908f-3902830d2b18",
   "metadata": {},
   "source": [
    "### Tratamiento de datos faltantes en el dataset diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4bfbac3-51b4-4b6b-8ceb-920aead48862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos por columna:\n",
      "FECHA                   0\n",
      "ESTACION                0\n",
      "TEMP_MEAN               8\n",
      "TEMP_MIN                8\n",
      "TEMP_MAX                8\n",
      "PNM_MEAN                8\n",
      "PNM_MIN                 8\n",
      "PNM_MAX                 8\n",
      "HUM_MEAN                8\n",
      "HUM_MIN                 8\n",
      "HUM_MAX                 8\n",
      "WIND_DIR_MEAN           8\n",
      "WIND_DIR_MIN            8\n",
      "WIND_DIR_MAX            8\n",
      "WIND_SPEED_MEAN         8\n",
      "WIND_SPEED_MIN          8\n",
      "WIND_SPEED_MAX          8\n",
      "TEMP_MEAN_NORM          8\n",
      "PNM_MEAN_NORM           8\n",
      "HUM_MEAN_NORM           8\n",
      "WIND_DIR_MEAN_NORM      8\n",
      "WIND_SPEED_MEAN_NORM    8\n",
      "dtype: int64\n",
      "\n",
      "Porcentaje de valores nulos:\n",
      "FECHA                   0.00\n",
      "ESTACION                0.00\n",
      "TEMP_MEAN               0.94\n",
      "TEMP_MIN                0.94\n",
      "TEMP_MAX                0.94\n",
      "PNM_MEAN                0.94\n",
      "PNM_MIN                 0.94\n",
      "PNM_MAX                 0.94\n",
      "HUM_MEAN                0.94\n",
      "HUM_MIN                 0.94\n",
      "HUM_MAX                 0.94\n",
      "WIND_DIR_MEAN           0.94\n",
      "WIND_DIR_MIN            0.94\n",
      "WIND_DIR_MAX            0.94\n",
      "WIND_SPEED_MEAN         0.94\n",
      "WIND_SPEED_MIN          0.94\n",
      "WIND_SPEED_MAX          0.94\n",
      "TEMP_MEAN_NORM          0.94\n",
      "PNM_MEAN_NORM           0.94\n",
      "HUM_MEAN_NORM           0.94\n",
      "WIND_DIR_MEAN_NORM      0.94\n",
      "WIND_SPEED_MEAN_NORM    0.94\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Visualizar cantidad de nulos por columna\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df_plata.isnull().sum())\n",
    "\n",
    "# Calcular porcentaje de nulos por columna\n",
    "porcentaje_nulos = df_plata.isnull().mean() * 100\n",
    "print(\"\\nPorcentaje de valores nulos:\")\n",
    "print(porcentaje_nulos.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8a240-a6f6-4609-b13c-0ea3aea43a1c",
   "metadata": {},
   "source": [
    "Una vez identificadas las columnas afectadas, proponemos distintas estrategias para completar los datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8c214-e0d0-4a2a-b7f6-6905872c9356",
   "metadata": {},
   "source": [
    "### Relleno con forward fill por estación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b407236-2e12-4451-9c17-492b77e80fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de datos tras forward fill:\n",
      "       FECHA       ESTACION  TEMP_MEAN  TEMP_MIN  TEMP_MAX  PNM_MEAN  PNM_MIN  PNM_MAX  HUM_MEAN  HUM_MIN  HUM_MAX  WIND_DIR_MEAN  WIND_DIR_MIN  WIND_DIR_MAX  WIND_SPEED_MEAN  WIND_SPEED_MIN  WIND_SPEED_MAX  TEMP_MEAN_NORM  PNM_MEAN_NORM  HUM_MEAN_NORM  WIND_DIR_MEAN_NORM  WIND_SPEED_MEAN_NORM\n",
      "0 2024-06-01  CHAPELCO AERO        4.1       1.8       6.6    1014.6   1011.7   1018.1      76.4     51.0     93.0          250.0           0.0         290.0             25.5             0.0            39.0        0.204301       0.406619       0.741148            0.774326              0.611650\n",
      "2 2024-06-02  CHAPELCO AERO        1.2      -2.2       5.2    1026.2   1019.1   1030.1      83.1     57.0     99.0          100.0           0.0         990.0              9.1             0.0            22.0        0.126344       0.680851       0.822955            0.298891              0.213592\n",
      "4 2024-06-03  CHAPELCO AERO        2.8      -1.7       4.8    1020.9   1016.6   1028.9      65.5     52.0     94.0           92.9           0.0         270.0             14.0             0.0            22.0        0.169355       0.555556       0.608059            0.276387              0.332524\n",
      "6 2024-06-04  CHAPELCO AERO        4.2      -0.9      12.4    1014.5   1011.8   1017.1      84.8     63.0     98.0           52.9           0.0         290.0              2.6             0.0            11.0        0.206989       0.404255       0.843712            0.149604              0.055825\n",
      "8 2024-06-05  CHAPELCO AERO        6.9       4.6       9.2    1009.8   1008.4   1012.3      96.5     94.0    100.0          127.0           0.0         990.0              4.5             0.0            11.0        0.279570       0.293144       0.986569            0.384469              0.101942\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por estación y fecha para aplicar forward fill correctamente\n",
    "df_plata_ffill = df_plata.sort_values(['ESTACION', 'FECHA']).copy()\n",
    "df_plata_ffill.update(df_plata.groupby('ESTACION').ffill())\n",
    "\n",
    "# Vista previa de ejemplo tras forward fill\n",
    "print(\"\\nEjemplo de datos tras forward fill:\")\n",
    "print(df_plata_ffill.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacaf95f-a649-4971-b4ee-9c042fe1db11",
   "metadata": {},
   "source": [
    "### Imputación con la media de cada estación (solo para columnas numéricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6159b92c-f4f2-4554-8400-2d043628374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos después de imputación con medias:\n",
      "TEMP_MEAN          0\n",
      "PNM_MEAN           0\n",
      "HUM_MEAN           0\n",
      "WIND_SPEED_MEAN    0\n",
      "WIND_DIR_MEAN      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputar con la media por estación\n",
    "columnas_a_imputar = ['TEMP_MEAN', 'PNM_MEAN', 'HUM_MEAN', 'WIND_SPEED_MEAN', 'WIND_DIR_MEAN']\n",
    "\n",
    "for col in columnas_a_imputar:\n",
    "    df_plata_ffill[col] = df_plata_ffill.groupby('ESTACION')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Verificar resultado tras imputación\n",
    "print(\"\\nValores nulos después de imputación con medias:\")\n",
    "print(df_plata_ffill[columnas_a_imputar].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908a838-a9c0-4c8f-b1f5-b6005cfa8706",
   "metadata": {},
   "source": [
    "Estas estrategias permiten garantizar que las variables derivadas a construir se basen en datos consistentes, sin afectar la distribución ni introducir sesgos evidentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e25e56-6de6-47c7-9d84-967dd5acbdd0",
   "metadata": {},
   "source": [
    "### Tratamiento de datos faltantes en el dataset horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbd7603-b5fb-446f-9f57-f12b36817782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diferencia de tamaño (horas originales vs completadas por horario habitual):\n",
      "Original: 19288\n",
      "Completo: 20448\n",
      "\n",
      "Ejemplo de datos horarios con NaN insertados:\n",
      "            NOMBRE          FECHA_HORA FECHA  HORA  TEMP  HUM  PNM  DD  FF  estacion_archivo\n",
      "476  CHAPELCO AERO 2024-06-20 20:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "477  CHAPELCO AERO 2024-06-20 21:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "478  CHAPELCO AERO 2024-06-20 22:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "479  CHAPELCO AERO 2024-06-20 23:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "480  CHAPELCO AERO 2024-06-21 00:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n"
     ]
    }
   ],
   "source": [
    "# Detectar horarios reales de cada estación\n",
    "df_horario['HORA'] = df_horario['FECHA_HORA'].dt.hour\n",
    "horarios_por_estacion = df_horario.groupby('NOMBRE')['HORA'].value_counts().unstack(fill_value=0)\n",
    "horarios_mas_frecuentes = horarios_por_estacion.idxmax(axis=1)\n",
    "\n",
    "# Detectar horarios outlier (menos del 5% de los días)\n",
    "outliers_horarios = {}\n",
    "for estacion in horarios_por_estacion.index:\n",
    "    total_dias = df_horario[df_horario['NOMBRE'] == estacion]['FECHA_HORA'].dt.date.nunique()\n",
    "    outliers = horarios_por_estacion.loc[estacion][\n",
    "        horarios_por_estacion.loc[estacion] / total_dias < 0.05\n",
    "    ].index.tolist()\n",
    "    if outliers:\n",
    "        outliers_horarios[estacion] = outliers\n",
    "\n",
    "# Crear index completo por estación y sus horarios típicos\n",
    "df_horario['FECHA'] = df_horario['FECHA_HORA'].dt.floor('D')\n",
    "estaciones_h = df_horario['NOMBRE'].unique()\n",
    "fecha_h_min = df_horario['FECHA'].min()\n",
    "fecha_h_max = df_horario['FECHA'].max()\n",
    "rango_fechas = pd.date_range(start=fecha_h_min, end=fecha_h_max, freq='D')\n",
    "\n",
    "# Crear combinaciones válidas por estación\n",
    "porcentaje_frecuencia = 0.05 # al menos en 5% de los días\n",
    "\n",
    "index_completo_personalizado = []\n",
    "for estacion in estaciones_h:\n",
    "    total_dias_estacion = df_horario[df_horario['NOMBRE'] == estacion]['FECHA'].nunique()\n",
    "    horas_validas = horarios_por_estacion.columns[\n",
    "        (horarios_por_estacion.loc[estacion] / total_dias_estacion) >= porcentaje_frecuencia  \n",
    "    ].tolist()\n",
    "\n",
    "    for fecha in rango_fechas:\n",
    "        for hora in horas_validas:\n",
    "            index_completo_personalizado.append((estacion, pd.Timestamp(fecha + pd.Timedelta(hours=hora))))\n",
    "\n",
    "index_completo_h = pd.MultiIndex.from_tuples(index_completo_personalizado, names=['NOMBRE', 'FECHA_HORA'])\n",
    "\n",
    "# Reindexar para insertar valores faltantes en los horarios esperados únicamente\n",
    "df_horario_completo = df_horario.set_index(['NOMBRE', 'FECHA_HORA']).reindex(index_completo_h).reset_index()\n",
    "\n",
    "# Verificación\n",
    "print(\"\\nDiferencia de tamaño (horas originales vs completadas por horario habitual):\")\n",
    "print(\"Original:\", len(df_horario))\n",
    "print(\"Completo:\", len(df_horario_completo))\n",
    "print(\"\\nEjemplo de datos horarios con NaN insertados:\")\n",
    "print(df_horario_completo[df_horario_completo.isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe64ec-63a1-4df4-99b5-7b3a8f844f5f",
   "metadata": {},
   "source": [
    "### Mostrar horarios outliers detectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efa97cf-8e8b-4e6d-bf2c-5f77410e2855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Registros reales en horarios atípicos:\n"
     ]
    }
   ],
   "source": [
    "# Visualizar registros reales en horarios atípicos detectados\n",
    "print(\"\\n Registros reales en horarios atípicos:\")\n",
    "for estacion, horas in outliers_horarios.items():\n",
    "    print(f\" - {estacion}: {horas}\")\n",
    "\n",
    "# Registrar los registros reales que ocurren en horarios atípicos\n",
    "df_outliers_registros = []\n",
    "for estacion, horas_outlier in outliers_horarios.items():\n",
    "    registros_outlier = df_horario[\n",
    "        (df_horario['NOMBRE'] == estacion) &\n",
    "        (df_horario['HORA'].isin(horas_outlier))\n",
    "    ]\n",
    "    if not registros_outlier.empty:\n",
    "        df_outliers_registros.append(registros_outlier)\n",
    "\n",
    "# Concatenar y exportar si hay registros\n",
    "if df_outliers_registros:\n",
    "    df_outliers_concat = pd.concat(df_outliers_registros)\n",
    "    archivo_outliers = PLATA_DIR / \"registros_horarios_atipicos.csv\"\n",
    "    df_outliers_concat.to_csv(archivo_outliers, index=False)\n",
    "    print(\"\\n Archivo exportado con registros reales en horarios atípicos:\")\n",
    "    print(archivo_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ab9e1-38b0-422b-8ac8-fabee6b2cc05",
   "metadata": {},
   "source": [
    "## Exportar datasets intermedios (antes de procesar los NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e123bf3d-a7ba-4ed6-b638-889d892267bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos generados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Exportar datasets intermedios (si se desea conservar)\n",
    "df_plata.to_csv(PLATA_DIR / \"dataset_intermedio_horario_con_nan.csv\", index=False)\n",
    "df_plata_ffill.to_csv(PLATA_DIR / \"dataset_intermedio_horario_ffill.csv\", index=False)\n",
    "df_horario_completo.to_csv(PLATA_DIR / \"dataset_intermedio_horario_completo.csv\", index=False)\n",
    "\n",
    "print(\"Archivos generados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387836d4-c0de-457a-b4ff-7db2548ab541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              NOMBRE          FECHA_HORA      FECHA  HORA  TEMP   HUM     PNM     DD    FF  estacion_archivo\n",
      "0      CHAPELCO AERO 2024-06-01 00:00:00 2024-06-01   0.0   5.2  85.0  1012.6  260.0  11.0        20240601.0\n",
      "1      CHAPELCO AERO 2024-06-01 01:00:00 2024-06-01   1.0   6.2  81.0  1012.3  270.0  22.0        20240601.0\n",
      "2      CHAPELCO AERO 2024-06-01 02:00:00 2024-06-01   2.0   6.0  75.0  1012.1  270.0  22.0        20240601.0\n",
      "3      CHAPELCO AERO 2024-06-01 03:00:00 2024-06-01   3.0   5.0  85.0  1011.7  270.0  31.0        20240601.0\n",
      "4      CHAPELCO AERO 2024-06-01 04:00:00 2024-06-01   4.0   4.8  88.0  1012.7  270.0  35.0        20240601.0\n",
      "...              ...                 ...        ...   ...   ...   ...     ...    ...   ...               ...\n",
      "20443   NEUQUEN AERO 2025-07-31 19:00:00 2025-07-31  19.0  11.4  85.0  1007.7    0.0   0.0        20250731.0\n",
      "20444   NEUQUEN AERO 2025-07-31 20:00:00 2025-07-31  20.0   9.8  90.0  1008.3  320.0   4.0        20250731.0\n",
      "20445   NEUQUEN AERO 2025-07-31 21:00:00 2025-07-31  21.0   9.7  90.0  1008.8   20.0   4.0        20250731.0\n",
      "20446   NEUQUEN AERO 2025-07-31 22:00:00 2025-07-31  22.0   9.2  92.0  1009.4    0.0   0.0        20250731.0\n",
      "20447   NEUQUEN AERO 2025-07-31 23:00:00 2025-07-31  23.0   8.0  96.0  1009.5    0.0   0.0        20250731.0\n",
      "\n",
      "[20448 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_horario_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b914b3-5333-417a-b3d7-4c406e1ee6ff",
   "metadata": {},
   "source": [
    "## Imputación de datos faltantes basada en promedio entre días anterior y posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c55f63-780e-4528-9572-12334333c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado: ../data/plata/dataset_plata_horario_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Variables a imputar\n",
    "variables_objetivo = ['TEMP', 'HUM', 'PNM', 'DD', 'FF']\n",
    "\n",
    "df_interp = df_horario_completo.copy()\n",
    "\n",
    "# Asegurar FECHA y HORA correctas\n",
    "df_interp['FECHA'] = df_interp['FECHA_HORA'].dt.date\n",
    "df_interp['HORA'] = df_interp['FECHA_HORA'].dt.hour\n",
    "\n",
    "# Ordenar por estación, fecha y hora\n",
    "df_interp = df_interp.sort_values(by=['NOMBRE', 'FECHA', 'HORA'])\n",
    "\n",
    "# Función de imputación por promedio entre día anterior y posterior\n",
    "def imputar_valores(grupo):\n",
    "    grupo = grupo.copy()  # para evitar advertencias de SettingWithCopy\n",
    "    for var in variables_objetivo:\n",
    "        for idx, fila in grupo.iterrows():\n",
    "            if pd.isna(fila[var]):\n",
    "                hora = fila['HORA']\n",
    "                fecha = fila['FECHA']\n",
    "\n",
    "                # Buscar el valor del día anterior\n",
    "                val_ant = grupo[(grupo['HORA'] == hora) & (grupo['FECHA'] < fecha)][var].last_valid_index()\n",
    "                val_ant = grupo.at[val_ant, var] if val_ant is not None else None\n",
    "\n",
    "                # Buscar el valor del día posterior\n",
    "                val_post = grupo[(grupo['HORA'] == hora) & (grupo['FECHA'] > fecha)][var].first_valid_index()\n",
    "                val_post = grupo.at[val_post, var] if val_post is not None else None\n",
    "\n",
    "                # Asignar promedio o valor disponible\n",
    "                if val_ant is not None and val_post is not None:\n",
    "                    grupo.at[idx, var] = round((val_ant + val_post) / 2, 1)\n",
    "                elif val_ant is not None:\n",
    "                    grupo.at[idx, var] = val_ant\n",
    "                elif val_post is not None:\n",
    "                    grupo.at[idx, var] = val_post\n",
    "    return grupo\n",
    "\n",
    "# Aplicar por estación SIN include_groups\n",
    "df_interp = (\n",
    "    df_interp.groupby('NOMBRE', group_keys=False)\n",
    "    .apply(imputar_valores)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Redondear valores numéricos a 1 decimal\n",
    "for var in variables_objetivo:\n",
    "    df_interp[var] = df_interp[var].round(1)\n",
    "\n",
    "# Ajustar tipos de columnas\n",
    "df_interp['HORA'] = df_interp['HORA'].astype('int64')\n",
    "if 'estacion_archivo' in df_interp.columns:\n",
    "    df_interp['estacion_archivo'] = df_interp['estacion_archivo'].astype('int64', errors='ignore')\n",
    "\n",
    "# Exportar\n",
    "archivo_imputado = PLATA_DIR / \"dataset_plata_horario_final.csv\"\n",
    "df_interp.to_csv(archivo_imputado, index=False)\n",
    "print(f\"Archivo exportado: {archivo_imputado}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601075f8-481b-4421-86ea-08dde5c8ec10",
   "metadata": {},
   "source": [
    "## Generar archivo diario a partir de la imputación de los datos faltantes en el dato_horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25ddba3-bd7d-4118-bc51-312318bc688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas finales: ['ESTACION', 'FECHA', 'TEMP_MEAN', 'TEMP_MIN', 'TEMP_MAX', 'PNM_MEAN', 'PNM_MIN', 'PNM_MAX', 'HUM_MEAN', 'HUM_MIN', 'HUM_MAX', 'WIND_DIR_MEAN', 'WIND_DIR_MIN', 'WIND_DIR_MAX', 'WIND_SPEED_MEAN', 'WIND_SPEED_MIN', 'WIND_SPEED_MAX', 'TEMP_MEAN_NORM', 'PNM_MEAN_NORM', 'HUM_MEAN_NORM', 'WIND_DIR_MEAN_NORM', 'WIND_SPEED_MEAN_NORM']\n",
      "Filas: 852 | Columnas: 22\n",
      "ESTACION\n",
      "CHAPELCO AERO    426\n",
      "NEUQUEN AERO     426\n",
      "dtype: int64\n",
      "Archivo diario imputado exportado: ../data/plata/dataset_plata_diario_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Generar dataset diario imputado (todas las estaciones)\n",
    "\n",
    "# Agrupar por estación y fecha\n",
    "df_diario_imputado = df_interp.groupby(['NOMBRE', 'FECHA']).agg(\n",
    "    TEMP_MEAN=('TEMP', 'mean'),\n",
    "    TEMP_MIN=('TEMP', 'min'),\n",
    "    TEMP_MAX=('TEMP', 'max'),\n",
    "    PNM_MEAN=('PNM', 'mean'),\n",
    "    PNM_MIN=('PNM', 'min'),\n",
    "    PNM_MAX=('PNM', 'max'),\n",
    "    HUM_MEAN=('HUM', 'mean'),\n",
    "    HUM_MIN=('HUM', 'min'),\n",
    "    HUM_MAX=('HUM', 'max'),\n",
    "    WIND_DIR_MEAN=('DD', 'mean'),\n",
    "    WIND_DIR_MIN=('DD', 'min'),\n",
    "    WIND_DIR_MAX=('DD', 'max'),\n",
    "    WIND_SPEED_MEAN=('FF', 'mean'),\n",
    "    WIND_SPEED_MIN=('FF', 'min'),\n",
    "    WIND_SPEED_MAX=('FF', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Renombrar y ordenar\n",
    "df_diario_imputado.rename(columns={'NOMBRE':'ESTACION'}, inplace=True)\n",
    "df_diario_imputado['FECHA'] = pd.to_datetime(df_diario_imputado['FECHA'])\n",
    "df_diario_imputado = df_diario_imputado.sort_values(by=['ESTACION','FECHA']).reset_index(drop=True)\n",
    "\n",
    "# Ajustes de tipos y redondeo\n",
    "\n",
    "# Redondear medias a 1 decimal\n",
    "cols_float = ['TEMP_MEAN','PNM_MEAN','HUM_MEAN','WIND_DIR_MEAN','WIND_SPEED_MEAN']\n",
    "df_diario_imputado[cols_float] = df_diario_imputado[cols_float].round(1)\n",
    "\n",
    "# Convertir min y max a enteros\n",
    "cols_int = [\n",
    "    'TEMP_MIN','TEMP_MAX','PNM_MIN','PNM_MAX',\n",
    "    'HUM_MIN','HUM_MAX',\n",
    "    'WIND_DIR_MIN','WIND_DIR_MAX',\n",
    "    'WIND_SPEED_MIN','WIND_SPEED_MAX'\n",
    "]\n",
    "df_diario_imputado[cols_int] = df_diario_imputado[cols_int].round().astype(int)\n",
    "\n",
    "# Normalización Min-Max de las variables MEAN\n",
    "\n",
    "variables_mean = ['TEMP_MEAN','PNM_MEAN','HUM_MEAN','WIND_DIR_MEAN','WIND_SPEED_MEAN']\n",
    "for var in variables_mean:\n",
    "    col_norm = var + '_NORM'\n",
    "    min_val = df_diario_imputado[var].min()\n",
    "    max_val = df_diario_imputado[var].max()\n",
    "    df_diario_imputado[col_norm] = ((df_diario_imputado[var] - min_val) / (max_val - min_val)).round(5)\n",
    "\n",
    "# Validación y exportación\n",
    "\n",
    "print(\"\\nColumnas finales:\", df_diario_imputado.columns.tolist())\n",
    "print(\"Filas:\", len(df_diario_imputado), \"| Columnas:\", len(df_diario_imputado.columns))\n",
    "print(df_diario_imputado.groupby('ESTACION').size())\n",
    "\n",
    "# Guardar el dataset diario imputado completo\n",
    "archivo_diario_imputado = PLATA_DIR / \"dataset_plata_diario_final.csv\"\n",
    "df_diario_imputado.to_csv(archivo_diario_imputado, index=False)\n",
    "print(f\"Archivo diario imputado exportado: {archivo_diario_imputado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5a1e2-540a-4687-a19e-2fbad388c299",
   "metadata": {},
   "source": [
    "## Verificar las imputaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6171ed-7840-45f6-bebd-8b074f8307f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores restantes faltantes por variable:\n",
      "TEMP    0\n",
      "HUM     0\n",
      "PNM     0\n",
      "DD      0\n",
      "FF      0\n",
      "dtype: int64\n",
      "\n",
      "Ejemplos de filas con valores aún faltantes:\n",
      "Empty DataFrame\n",
      "Columns: [NOMBRE, FECHA_HORA, FECHA, HORA, TEMP, HUM, PNM, DD, FF, estacion_archivo]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Verificación de imputación final\n",
    "print(\"Valores restantes faltantes por variable:\")\n",
    "print(df_interp[variables_objetivo].isnull().sum())\n",
    "\n",
    "# Vista previa de algunos valores aún faltantes (si existen)\n",
    "print(\"\\nEjemplos de filas con valores aún faltantes:\")\n",
    "print(df_interp[df_interp[variables_objetivo].isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582557e9-6395-4024-bf21-354896d3d44d",
   "metadata": {},
   "source": [
    "# Contar imputaciones por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b35aff0-0b2a-4654-b75a-2da41925b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de imputaciones por variable:\n",
      " - TEMP: 1160 valores imputados\n",
      " - HUM: 1160 valores imputados\n",
      " - PNM: 1160 valores imputados\n",
      " - DD: 1160 valores imputados\n",
      " - FF: 1160 valores imputados\n",
      "\n",
      "Ejemplos de imputaciones realizadas:\n",
      "\n",
      "Variable: TEMP\n",
      "               FECHA_HORA         NOMBRE  TEMP\n",
      "476   2024-06-20 20:00:00  CHAPELCO AERO   0.7\n",
      "477   2024-06-20 21:00:00  CHAPELCO AERO   0.3\n",
      "478   2024-06-20 22:00:00  CHAPELCO AERO   0.6\n",
      "479   2024-06-20 23:00:00  CHAPELCO AERO   0.6\n",
      "480   2024-06-21 00:00:00  CHAPELCO AERO   0.7\n",
      "...                   ...            ...   ...\n",
      "19380 2025-06-17 12:00:00   NEUQUEN AERO   8.5\n",
      "19406 2025-06-18 14:00:00   NEUQUEN AERO  12.1\n",
      "19687 2025-06-30 07:00:00   NEUQUEN AERO  -7.6\n",
      "19688 2025-06-30 08:00:00   NEUQUEN AERO  -7.8\n",
      "19689 2025-06-30 09:00:00   NEUQUEN AERO  -7.3\n",
      "\n",
      "[1160 rows x 3 columns]\n",
      "\n",
      "Variable: HUM\n",
      "               FECHA_HORA         NOMBRE    HUM\n",
      "476   2024-06-20 20:00:00  CHAPELCO AERO   89.5\n",
      "477   2024-06-20 21:00:00  CHAPELCO AERO   92.5\n",
      "478   2024-06-20 22:00:00  CHAPELCO AERO   91.0\n",
      "479   2024-06-20 23:00:00  CHAPELCO AERO   89.5\n",
      "480   2024-06-21 00:00:00  CHAPELCO AERO   91.0\n",
      "...                   ...            ...    ...\n",
      "19380 2025-06-17 12:00:00   NEUQUEN AERO   53.0\n",
      "19406 2025-06-18 14:00:00   NEUQUEN AERO   43.5\n",
      "19687 2025-06-30 07:00:00   NEUQUEN AERO   97.0\n",
      "19688 2025-06-30 08:00:00   NEUQUEN AERO   97.0\n",
      "19689 2025-06-30 09:00:00   NEUQUEN AERO  100.0\n",
      "\n",
      "[1160 rows x 3 columns]\n",
      "\n",
      "Variable: PNM\n",
      "               FECHA_HORA         NOMBRE     PNM\n",
      "476   2024-06-20 20:00:00  CHAPELCO AERO  1013.0\n",
      "477   2024-06-20 21:00:00  CHAPELCO AERO  1012.6\n",
      "478   2024-06-20 22:00:00  CHAPELCO AERO  1012.6\n",
      "479   2024-06-20 23:00:00  CHAPELCO AERO  1012.4\n",
      "480   2024-06-21 00:00:00  CHAPELCO AERO  1012.8\n",
      "...                   ...            ...     ...\n",
      "19380 2025-06-17 12:00:00   NEUQUEN AERO  1019.6\n",
      "19406 2025-06-18 14:00:00   NEUQUEN AERO  1020.8\n",
      "19687 2025-06-30 07:00:00   NEUQUEN AERO  1033.8\n",
      "19688 2025-06-30 08:00:00   NEUQUEN AERO  1034.2\n",
      "19689 2025-06-30 09:00:00   NEUQUEN AERO  1034.4\n",
      "\n",
      "[1160 rows x 3 columns]\n",
      "\n",
      "Variable: DD\n",
      "               FECHA_HORA         NOMBRE     DD\n",
      "476   2024-06-20 20:00:00  CHAPELCO AERO    0.0\n",
      "477   2024-06-20 21:00:00  CHAPELCO AERO    0.0\n",
      "478   2024-06-20 22:00:00  CHAPELCO AERO    0.0\n",
      "479   2024-06-20 23:00:00  CHAPELCO AERO    0.0\n",
      "480   2024-06-21 00:00:00  CHAPELCO AERO   40.0\n",
      "...                   ...            ...    ...\n",
      "19380 2025-06-17 12:00:00   NEUQUEN AERO  260.0\n",
      "19406 2025-06-18 14:00:00   NEUQUEN AERO  260.0\n",
      "19687 2025-06-30 07:00:00   NEUQUEN AERO  135.0\n",
      "19688 2025-06-30 08:00:00   NEUQUEN AERO  145.0\n",
      "19689 2025-06-30 09:00:00   NEUQUEN AERO   70.0\n",
      "\n",
      "[1160 rows x 3 columns]\n",
      "\n",
      "Variable: FF\n",
      "               FECHA_HORA         NOMBRE    FF\n",
      "476   2024-06-20 20:00:00  CHAPELCO AERO   0.0\n",
      "477   2024-06-20 21:00:00  CHAPELCO AERO   0.0\n",
      "478   2024-06-20 22:00:00  CHAPELCO AERO   0.0\n",
      "479   2024-06-20 23:00:00  CHAPELCO AERO   0.0\n",
      "480   2024-06-21 00:00:00  CHAPELCO AERO  12.0\n",
      "...                   ...            ...   ...\n",
      "19380 2025-06-17 12:00:00   NEUQUEN AERO   6.0\n",
      "19406 2025-06-18 14:00:00   NEUQUEN AERO  10.5\n",
      "19687 2025-06-30 07:00:00   NEUQUEN AERO   3.0\n",
      "19688 2025-06-30 08:00:00   NEUQUEN AERO   3.0\n",
      "19689 2025-06-30 09:00:00   NEUQUEN AERO   4.5\n",
      "\n",
      "[1160 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "imputaciones = {}\n",
    "for var in variables_objetivo:\n",
    "    # Detectar índices donde original es NaN pero imputado tiene valor\n",
    "    mask_imputado = df_horario_completo[var].isna() & df_interp[var].notna()\n",
    "    imputaciones[var] = mask_imputado.sum()\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"Resumen de imputaciones por variable:\")\n",
    "for var, count in imputaciones.items():\n",
    "    print(f\" - {var}: {count} valores imputados\")\n",
    "\n",
    "# Mostrar ejemplos comparativos (solo filas donde hubo imputación)\n",
    "print(\"\\nEjemplos de imputaciones realizadas:\")\n",
    "for var in variables_objetivo:\n",
    "    mask = df_horario_completo[var].isna() & df_interp[var].notna()\n",
    "    if mask.any():\n",
    "        print(f\"\\nVariable: {var}\")\n",
    "        print(df_interp.loc[mask, ['FECHA_HORA', 'NOMBRE', var]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2e28a-e09d-4f54-931b-233ace89e1c0",
   "metadata": {},
   "source": [
    "# Visualización de imputación de los días faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fde00ba-b535-4101-aa38-7764982715d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Estación: NEUQUEN AERO ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA        NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "13704 2024-10-24 00:00:00  NEUQUEN AERO  16.8  45.0  1011.8  115.0  11.0\n",
      "13705 2024-10-24 01:00:00  NEUQUEN AERO  15.4  57.0  1012.0  115.0  13.0\n",
      "13706 2024-10-24 02:00:00  NEUQUEN AERO  14.5  56.5  1012.2  135.0  11.0\n",
      "13707 2024-10-24 03:00:00  NEUQUEN AERO  13.2  57.5  1012.0  135.0   9.5\n",
      "13708 2024-10-24 04:00:00  NEUQUEN AERO  13.8  59.0  1012.2  115.0  10.0\n",
      "13709 2024-10-24 05:00:00  NEUQUEN AERO  14.7  45.0  1013.0  240.0  11.5\n",
      "13710 2024-10-24 06:00:00  NEUQUEN AERO  14.6  51.0  1013.6  260.0   9.5\n",
      "13711 2024-10-24 07:00:00  NEUQUEN AERO  14.3  54.0  1014.2  250.0  12.0\n",
      "13712 2024-10-24 08:00:00  NEUQUEN AERO  15.2  52.0  1014.8  235.0  16.0\n",
      "13713 2024-10-24 09:00:00  NEUQUEN AERO  16.0  51.0  1015.4  260.0  18.0\n",
      "13714 2024-10-24 10:00:00  NEUQUEN AERO  17.8  43.0  1015.2  230.0  17.0\n",
      "13715 2024-10-24 11:00:00  NEUQUEN AERO  19.2  38.0  1014.8  235.0  17.0\n",
      "13716 2024-10-24 12:00:00  NEUQUEN AERO  20.8  35.5  1014.4  250.0  17.0\n",
      "13717 2024-10-24 13:00:00  NEUQUEN AERO  21.5  33.5  1013.6  265.0  18.5\n",
      "13718 2024-10-24 14:00:00  NEUQUEN AERO  22.5  29.5  1012.4  290.0  23.0\n",
      "13719 2024-10-24 15:00:00  NEUQUEN AERO  23.1  28.0  1011.7  260.0  20.5\n",
      "13720 2024-10-24 16:00:00  NEUQUEN AERO  23.2  27.5  1010.8  275.0  22.0\n",
      "13721 2024-10-24 17:00:00  NEUQUEN AERO  23.9  26.0  1010.1  285.0  19.5\n",
      "13722 2024-10-24 18:00:00  NEUQUEN AERO  24.2  25.5  1009.8  280.0  24.0\n",
      "13723 2024-10-24 19:00:00  NEUQUEN AERO  23.7  23.5  1009.6  260.0  23.5\n",
      "13724 2024-10-24 20:00:00  NEUQUEN AERO  22.5  28.0  1010.2  270.0  22.0\n",
      "13725 2024-10-24 21:00:00  NEUQUEN AERO  21.2  30.0  1011.2  295.0  21.5\n",
      "13726 2024-10-24 22:00:00  NEUQUEN AERO  20.2  33.5  1012.3  250.0  14.5\n",
      "13727 2024-10-24 23:00:00  NEUQUEN AERO  19.7  32.0  1012.8  250.0  19.5\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA        NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "14688 2024-12-04 00:00:00  NEUQUEN AERO  17.1  39.0  1010.8  115.0   5.5\n",
      "14689 2024-12-04 01:00:00  NEUQUEN AERO  17.0  35.5  1011.0  185.0  10.5\n",
      "14690 2024-12-04 02:00:00  NEUQUEN AERO  15.2  50.0  1010.9  250.0   9.0\n",
      "14691 2024-12-04 03:00:00  NEUQUEN AERO  15.5  47.0  1010.4  250.0  11.0\n",
      "14692 2024-12-04 04:00:00  NEUQUEN AERO  13.4  51.5  1010.3  260.0  11.0\n",
      "14693 2024-12-04 05:00:00  NEUQUEN AERO  13.3  49.5  1010.6  270.0   5.5\n",
      "14694 2024-12-04 06:00:00  NEUQUEN AERO  12.1  48.0  1011.2  100.0   3.0\n",
      "14695 2024-12-04 07:00:00  NEUQUEN AERO  12.8  48.0  1011.8  160.0   3.0\n",
      "14696 2024-12-04 08:00:00  NEUQUEN AERO  15.1  50.0  1012.1  320.0   5.0\n",
      "14697 2024-12-04 09:00:00  NEUQUEN AERO  18.9  36.5  1012.0  240.0   8.0\n",
      "14698 2024-12-04 10:00:00  NEUQUEN AERO  20.8  32.0  1011.8  230.0   8.0\n",
      "14699 2024-12-04 11:00:00  NEUQUEN AERO  22.2  27.0  1011.0  235.0   9.5\n",
      "14700 2024-12-04 12:00:00  NEUQUEN AERO  23.0  28.0  1010.6  270.0  12.0\n",
      "14701 2024-12-04 13:00:00  NEUQUEN AERO  24.4  22.0  1009.8  260.0  10.5\n",
      "14702 2024-12-04 14:00:00  NEUQUEN AERO  25.7  22.0  1008.6  240.0   9.0\n",
      "14703 2024-12-04 15:00:00  NEUQUEN AERO  25.6  19.5  1008.0  205.0  10.5\n",
      "14704 2024-12-04 16:00:00  NEUQUEN AERO  26.4  20.0  1007.2  240.0  13.0\n",
      "14705 2024-12-04 17:00:00  NEUQUEN AERO  26.5  21.0  1006.8  215.0  14.5\n",
      "14706 2024-12-04 18:00:00  NEUQUEN AERO  26.1  19.0  1006.6  215.0  14.0\n",
      "14707 2024-12-04 19:00:00  NEUQUEN AERO  25.4  19.0  1006.6  160.0  11.5\n",
      "14708 2024-12-04 20:00:00  NEUQUEN AERO  24.4  20.0  1007.1  170.0  14.0\n",
      "14709 2024-12-04 21:00:00  NEUQUEN AERO  22.0  27.0  1007.8  115.0   9.5\n",
      "14710 2024-12-04 22:00:00  NEUQUEN AERO  18.8  35.0  1008.7  125.0  10.0\n",
      "14711 2024-12-04 23:00:00  NEUQUEN AERO  17.6  43.5  1009.6  135.0   6.5\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA        NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "14856 2024-12-11 00:00:00  NEUQUEN AERO  18.2  58.0  1011.2   45.0   3.0\n",
      "14857 2024-12-11 01:00:00  NEUQUEN AERO  18.1  54.5  1011.2  215.0   6.5\n",
      "14858 2024-12-11 02:00:00  NEUQUEN AERO  15.8  62.0  1011.5  145.0   3.5\n",
      "14859 2024-12-11 03:00:00  NEUQUEN AERO  15.0  64.5  1011.2   90.0   3.0\n",
      "14860 2024-12-11 04:00:00  NEUQUEN AERO  15.0  64.0  1010.6   90.0   3.5\n",
      "14861 2024-12-11 05:00:00  NEUQUEN AERO  15.2  66.5  1010.8  140.0   5.0\n",
      "14862 2024-12-11 06:00:00  NEUQUEN AERO  14.9  67.5  1011.0  150.0   5.5\n",
      "14863 2024-12-11 07:00:00  NEUQUEN AERO  15.8  62.5  1011.2   70.0   3.0\n",
      "14864 2024-12-11 08:00:00  NEUQUEN AERO  17.6  61.5  1011.1  140.0   7.0\n",
      "14865 2024-12-11 09:00:00  NEUQUEN AERO  19.8  59.0  1011.1  100.0  10.0\n",
      "14866 2024-12-11 10:00:00  NEUQUEN AERO  22.4  54.0  1010.4  115.0   6.5\n",
      "14867 2024-12-11 11:00:00  NEUQUEN AERO  24.5  50.5  1009.8  250.0   6.5\n",
      "14868 2024-12-11 12:00:00  NEUQUEN AERO  27.0  42.0  1009.0   60.0   3.0\n",
      "14869 2024-12-11 13:00:00  NEUQUEN AERO  28.4  43.0  1008.0  235.0   6.5\n",
      "14870 2024-12-11 14:00:00  NEUQUEN AERO  30.4  40.0  1006.6  240.0   6.0\n",
      "14871 2024-12-11 15:00:00  NEUQUEN AERO  31.4  36.0  1005.6  245.0   9.5\n",
      "14872 2024-12-11 16:00:00  NEUQUEN AERO  32.8  28.5  1005.0  270.0  15.5\n",
      "14873 2024-12-11 17:00:00  NEUQUEN AERO  32.8  28.5  1004.4  205.0  13.0\n",
      "14874 2024-12-11 18:00:00  NEUQUEN AERO  33.2   9.5  1004.2  220.0  14.0\n",
      "14875 2024-12-11 19:00:00  NEUQUEN AERO  32.7  11.5  1004.0  215.0  11.5\n",
      "14876 2024-12-11 20:00:00  NEUQUEN AERO  32.2  15.0  1004.4  240.0   9.5\n",
      "14877 2024-12-11 21:00:00  NEUQUEN AERO  29.4  16.0  1005.6  240.0  14.5\n",
      "14878 2024-12-11 22:00:00  NEUQUEN AERO  26.4  20.0  1007.4  240.0  25.0\n",
      "14879 2024-12-11 23:00:00  NEUQUEN AERO  24.9  21.5  1008.4  240.0  23.0\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "               FECHA_HORA        NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "15720 2025-01-16 00:00:00  NEUQUEN AERO  22.6  45.5  1011.2  115.0   3.0\n",
      "15721 2025-01-16 01:00:00  NEUQUEN AERO  22.4  46.0  1010.9  270.0   4.0\n",
      "15722 2025-01-16 02:00:00  NEUQUEN AERO  21.8  48.0  1010.6  135.0   3.5\n",
      "15723 2025-01-16 03:00:00  NEUQUEN AERO  21.5  44.0  1010.2  295.0  10.0\n",
      "15724 2025-01-16 04:00:00  NEUQUEN AERO  20.8  43.0  1010.2  135.0   3.0\n",
      "15725 2025-01-16 05:00:00  NEUQUEN AERO  20.0  47.0  1010.3  135.0   3.0\n",
      "15726 2025-01-16 06:00:00  NEUQUEN AERO  20.2  50.5  1010.4  135.0   3.5\n",
      "15727 2025-01-16 07:00:00  NEUQUEN AERO  20.4  48.0  1010.5  295.0   8.5\n",
      "15728 2025-01-16 08:00:00  NEUQUEN AERO  23.0  39.0  1010.8  270.0  13.0\n",
      "15729 2025-01-16 09:00:00  NEUQUEN AERO  25.6  32.0  1011.0  260.0  16.0\n",
      "15730 2025-01-16 10:00:00  NEUQUEN AERO  26.6  29.5  1011.1  250.0  16.5\n",
      "15731 2025-01-16 11:00:00  NEUQUEN AERO  29.4  23.5  1010.6  270.0  19.5\n",
      "15732 2025-01-16 12:00:00  NEUQUEN AERO  29.9  24.5  1010.3  270.0  14.5\n",
      "15733 2025-01-16 13:00:00  NEUQUEN AERO  30.4  23.0  1009.8  280.0  19.5\n",
      "15734 2025-01-16 14:00:00  NEUQUEN AERO  31.7  22.0  1009.2  170.0  14.0\n",
      "15735 2025-01-16 15:00:00  NEUQUEN AERO  31.8  23.0  1008.6  265.0  13.0\n",
      "15736 2025-01-16 16:00:00  NEUQUEN AERO  32.1  25.0  1008.4  260.0  10.0\n",
      "15737 2025-01-16 17:00:00  NEUQUEN AERO  31.4  27.0  1008.2  215.0   7.5\n",
      "15738 2025-01-16 18:00:00  NEUQUEN AERO  31.2  25.5  1008.1  180.0   8.5\n",
      "15739 2025-01-16 19:00:00  NEUQUEN AERO  31.4  22.0  1008.3  225.0  11.5\n",
      "15740 2025-01-16 20:00:00  NEUQUEN AERO  30.4  26.0  1008.5  115.0  12.0\n",
      "15741 2025-01-16 21:00:00  NEUQUEN AERO  27.6  29.5  1009.6  100.0  12.0\n",
      "15742 2025-01-16 22:00:00  NEUQUEN AERO  25.6  33.5  1010.4  260.0  16.0\n",
      "15743 2025-01-16 23:00:00  NEUQUEN AERO  22.8  39.0  1011.6  235.0  16.5\n",
      "\n",
      "=== Estación: CHAPELCO AERO ===\n",
      "\n",
      "Fecha 2024-10-24 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA         NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "3480 2024-10-24 00:00:00  CHAPELCO AERO   8.6  65.0  1013.6  305.0  15.0\n",
      "3481 2024-10-24 01:00:00  CHAPELCO AERO   9.1  66.0  1014.0  275.0  10.0\n",
      "3482 2024-10-24 02:00:00  CHAPELCO AERO   7.2  71.5  1014.2  320.0  20.5\n",
      "3483 2024-10-24 03:00:00  CHAPELCO AERO   6.8  73.5  1014.0  290.0  12.0\n",
      "3484 2024-10-24 04:00:00  CHAPELCO AERO   6.5  76.5  1013.9  315.0  11.0\n",
      "3485 2024-10-24 05:00:00  CHAPELCO AERO   6.0  77.0  1014.8  285.0  15.0\n",
      "3486 2024-10-24 06:00:00  CHAPELCO AERO   7.3  74.0  1014.8  260.0  14.0\n",
      "3487 2024-10-24 07:00:00  CHAPELCO AERO   8.6  75.5  1015.4  285.0  23.0\n",
      "3488 2024-10-24 08:00:00  CHAPELCO AERO   8.8  78.5  1016.2  285.0  25.0\n",
      "3489 2024-10-24 09:00:00  CHAPELCO AERO  10.9  68.0  1016.1  280.0  35.0\n",
      "3490 2024-10-24 10:00:00  CHAPELCO AERO  11.9  60.5  1016.0  290.0  32.5\n",
      "3491 2024-10-24 11:00:00  CHAPELCO AERO  14.0  49.0  1015.8  305.0  35.0\n",
      "3492 2024-10-24 12:00:00  CHAPELCO AERO  16.3  43.0  1015.4  290.0  33.0\n",
      "3493 2024-10-24 13:00:00  CHAPELCO AERO  16.8  40.5  1015.1  280.0  39.0\n",
      "3494 2024-10-24 14:00:00  CHAPELCO AERO  17.5  36.5  1014.9  320.0  39.0\n",
      "3495 2024-10-24 15:00:00  CHAPELCO AERO  18.1  33.0  1014.6  305.0  37.0\n",
      "3496 2024-10-24 16:00:00  CHAPELCO AERO  18.1  31.0  1014.2  305.0  46.5\n",
      "3497 2024-10-24 17:00:00  CHAPELCO AERO  16.4  35.0  1015.2  320.0  47.5\n",
      "3498 2024-10-24 18:00:00  CHAPELCO AERO  15.3  40.0  1015.5  320.0  39.0\n",
      "3499 2024-10-24 19:00:00  CHAPELCO AERO  14.1  44.0  1016.3  320.0  35.0\n",
      "3500 2024-10-24 20:00:00  CHAPELCO AERO  12.2  50.5  1017.2  290.0  33.0\n",
      "3501 2024-10-24 21:00:00  CHAPELCO AERO  11.0  52.5  1017.8  290.0  25.0\n",
      "3502 2024-10-24 22:00:00  CHAPELCO AERO  10.1  57.0  1018.4  295.0  17.5\n",
      "3503 2024-10-24 23:00:00  CHAPELCO AERO   9.8  56.5  1018.0  305.0  33.5\n",
      "\n",
      "Fecha 2024-12-04 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA         NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "4464 2024-12-04 00:00:00  CHAPELCO AERO  10.0  57.0  1012.6  640.0  15.5\n",
      "4465 2024-12-04 01:00:00  CHAPELCO AERO   9.3  60.5  1012.3  280.0  17.0\n",
      "4466 2024-12-04 02:00:00  CHAPELCO AERO   8.6  64.0  1012.0  260.0  17.0\n",
      "4467 2024-12-04 03:00:00  CHAPELCO AERO   7.9  66.5  1011.6  260.0  17.5\n",
      "4468 2024-12-04 04:00:00  CHAPELCO AERO   7.2  73.5  1011.6  275.0  14.0\n",
      "4469 2024-12-04 05:00:00  CHAPELCO AERO   6.7  77.5  1011.4  300.0  14.0\n",
      "4470 2024-12-04 06:00:00  CHAPELCO AERO   6.0  83.0  1011.9  270.0  14.0\n",
      "4471 2024-12-04 07:00:00  CHAPELCO AERO   4.8  74.5  1012.6  280.0  17.0\n",
      "4472 2024-12-04 08:00:00  CHAPELCO AERO   7.4  66.5  1012.4  295.0  15.5\n",
      "4473 2024-12-04 09:00:00  CHAPELCO AERO  10.0  59.0  1012.2  140.0  11.0\n",
      "4474 2024-12-04 10:00:00  CHAPELCO AERO  11.5  50.5  1011.9  140.0  10.0\n",
      "4475 2024-12-04 11:00:00  CHAPELCO AERO  13.8  46.0  1011.4  195.0  16.5\n",
      "4476 2024-12-04 12:00:00  CHAPELCO AERO  15.1  40.0  1011.0  640.0  17.5\n",
      "4477 2024-12-04 13:00:00  CHAPELCO AERO  17.0  33.5  1010.3  265.0  22.0\n",
      "4478 2024-12-04 14:00:00  CHAPELCO AERO  17.4  30.0  1009.8  285.0  24.0\n",
      "4479 2024-12-04 15:00:00  CHAPELCO AERO  18.7  29.0  1008.9  290.0  31.5\n",
      "4480 2024-12-04 16:00:00  CHAPELCO AERO  18.8  28.5  1008.8  295.0  40.0\n",
      "4481 2024-12-04 17:00:00  CHAPELCO AERO  19.1  30.0  1009.2  300.0  35.5\n",
      "4482 2024-12-04 18:00:00  CHAPELCO AERO  17.3  33.5  1009.6  300.0  32.5\n",
      "4483 2024-12-04 19:00:00  CHAPELCO AERO  16.4  35.0  1010.6  315.0  37.5\n",
      "4484 2024-12-04 20:00:00  CHAPELCO AERO  14.8  38.5  1010.8  310.0  30.5\n",
      "4485 2024-12-04 21:00:00  CHAPELCO AERO  12.9  52.5  1011.0  285.0  22.5\n",
      "4486 2024-12-04 22:00:00  CHAPELCO AERO  11.8  60.5  1011.5  295.0  23.0\n",
      "4487 2024-12-04 23:00:00  CHAPELCO AERO  10.8  60.5  1011.8  290.0  20.5\n",
      "\n",
      "Fecha 2024-12-11 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA         NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "4632 2024-12-11 00:00:00  CHAPELCO AERO  13.5  54.0  1011.8  275.0  23.5\n",
      "4633 2024-12-11 01:00:00  CHAPELCO AERO  12.8  55.5  1011.4  285.0  18.5\n",
      "4634 2024-12-11 02:00:00  CHAPELCO AERO  11.9  55.0  1011.2  265.0  12.0\n",
      "4635 2024-12-11 03:00:00  CHAPELCO AERO  10.0  75.0  1010.8  250.0  10.5\n",
      "4636 2024-12-11 04:00:00  CHAPELCO AERO   9.3  82.0  1010.5  260.0  15.5\n",
      "4637 2024-12-11 05:00:00  CHAPELCO AERO   8.4  82.5  1010.8  300.0  15.5\n",
      "4638 2024-12-11 06:00:00  CHAPELCO AERO   7.7  75.0  1011.2  280.0  11.0\n",
      "4639 2024-12-11 07:00:00  CHAPELCO AERO   7.2  80.0  1011.8  285.0  11.0\n",
      "4640 2024-12-11 08:00:00  CHAPELCO AERO  10.1  70.0  1011.6  265.0  12.0\n",
      "4641 2024-12-11 09:00:00  CHAPELCO AERO  12.1  62.0  1011.4  260.0  16.5\n",
      "4642 2024-12-11 10:00:00  CHAPELCO AERO  15.1  49.0  1011.0  140.0  10.0\n",
      "4643 2024-12-11 11:00:00  CHAPELCO AERO  18.0  23.0  1010.2  285.0  28.5\n",
      "4644 2024-12-11 12:00:00  CHAPELCO AERO  20.0  21.0  1009.8  285.0  27.5\n",
      "4645 2024-12-11 13:00:00  CHAPELCO AERO  21.3  21.5  1009.2  280.0  32.5\n",
      "4646 2024-12-11 14:00:00  CHAPELCO AERO  22.7  13.5  1008.9  270.0  34.0\n",
      "4647 2024-12-11 15:00:00  CHAPELCO AERO  23.3  15.5  1009.0  280.0  31.5\n",
      "4648 2024-12-11 16:00:00  CHAPELCO AERO  23.0  16.5  1009.4  280.0  33.5\n",
      "4649 2024-12-11 17:00:00  CHAPELCO AERO  21.0  19.5  1010.2  290.0  34.0\n",
      "4650 2024-12-11 18:00:00  CHAPELCO AERO  20.1  20.0  1010.6  290.0  34.0\n",
      "4651 2024-12-11 19:00:00  CHAPELCO AERO  19.0  29.5  1011.4  285.0  37.0\n",
      "4652 2024-12-11 20:00:00  CHAPELCO AERO  16.9  40.5  1012.4  285.0  32.5\n",
      "4653 2024-12-11 21:00:00  CHAPELCO AERO  15.6  46.0  1012.8  290.0  21.0\n",
      "4654 2024-12-11 22:00:00  CHAPELCO AERO  14.7  52.0  1013.1  280.0  18.0\n",
      "4655 2024-12-11 23:00:00  CHAPELCO AERO  14.1  54.5  1013.5  290.0  17.5\n",
      "\n",
      "Fecha 2025-01-16 imputada correctamente\n",
      "\n",
      "--- Antes (Original con NaN) ---\n",
      "Empty DataFrame\n",
      "Columns: [FECHA_HORA, NOMBRE, TEMP, HUM, PNM, DD, FF]\n",
      "Index: []\n",
      "\n",
      "--- Después (Imputado) ---\n",
      "              FECHA_HORA         NOMBRE  TEMP   HUM     PNM     DD    FF\n",
      "5496 2025-01-16 00:00:00  CHAPELCO AERO  14.5  72.5  1011.8  295.0  20.5\n",
      "5497 2025-01-16 01:00:00  CHAPELCO AERO  14.5  72.5  1011.2  285.0  24.0\n",
      "5498 2025-01-16 02:00:00  CHAPELCO AERO  14.5  71.0  1010.8  280.0  24.0\n",
      "5499 2025-01-16 03:00:00  CHAPELCO AERO  13.7  76.0  1010.6  270.0  19.0\n",
      "5500 2025-01-16 04:00:00  CHAPELCO AERO  13.8  73.0  1010.4  295.0  20.0\n",
      "5501 2025-01-16 05:00:00  CHAPELCO AERO  13.2  76.5  1010.5  295.0  27.0\n",
      "5502 2025-01-16 06:00:00  CHAPELCO AERO  12.5  77.0  1011.0  295.0  24.0\n",
      "5503 2025-01-16 07:00:00  CHAPELCO AERO  12.0  76.5  1011.6  160.0  18.5\n",
      "5504 2025-01-16 08:00:00  CHAPELCO AERO  13.0  74.0  1012.2  160.0  15.0\n",
      "5505 2025-01-16 09:00:00  CHAPELCO AERO  14.8  65.0  1012.1  340.0  21.0\n",
      "5506 2025-01-16 10:00:00  CHAPELCO AERO  16.0  55.5  1012.6  300.0  25.0\n",
      "5507 2025-01-16 11:00:00  CHAPELCO AERO  17.5  47.0  1012.3  305.0  32.5\n",
      "5508 2025-01-16 12:00:00  CHAPELCO AERO  18.3  44.5  1012.0  295.0  35.5\n",
      "5509 2025-01-16 13:00:00  CHAPELCO AERO  19.1  40.5  1012.0  300.0  34.5\n",
      "5510 2025-01-16 14:00:00  CHAPELCO AERO  21.3  32.0  1011.4  300.0  37.0\n",
      "5511 2025-01-16 15:00:00  CHAPELCO AERO  22.0  28.5  1011.5  300.0  37.0\n",
      "5512 2025-01-16 16:00:00  CHAPELCO AERO  21.8  30.0  1011.8  310.0  37.0\n",
      "5513 2025-01-16 17:00:00  CHAPELCO AERO  21.3  31.5  1012.2  300.0  40.0\n",
      "5514 2025-01-16 18:00:00  CHAPELCO AERO  20.9  32.5  1012.6  305.0  30.5\n",
      "5515 2025-01-16 19:00:00  CHAPELCO AERO  20.4  33.5  1013.0  295.0  32.0\n",
      "5516 2025-01-16 20:00:00  CHAPELCO AERO  18.5  40.5  1013.7  305.0  28.0\n",
      "5517 2025-01-16 21:00:00  CHAPELCO AERO  16.4  47.5  1014.4  305.0  28.5\n",
      "5518 2025-01-16 22:00:00  CHAPELCO AERO  14.8  53.5  1015.4  300.0  20.5\n",
      "5519 2025-01-16 23:00:00  CHAPELCO AERO  13.5  55.5  1016.0  305.0  26.0\n",
      "\n",
      "Resumen de verificación de imputaciones por estación:\n",
      "        Estación  Total días faltantes  Días completos  Días con NaN\n",
      "0   NEUQUEN AERO                     4               4             0\n",
      "1  CHAPELCO AERO                     4               4             0\n"
     ]
    }
   ],
   "source": [
    "# Carpeta con los archivos de días faltantes\n",
    "FALTANTES_DIR = Path(\"../data/faltantes\")  # Ajustar al directorio correcto\n",
    "variables_objetivo = ['TEMP', 'HUM', 'PNM', 'DD', 'FF']\n",
    "\n",
    "# Función para leer días faltantes de un archivo\n",
    "def leer_dias_faltantes(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    fechas = [line.strip() for line in lines if line.strip() and line.strip()[0].isdigit()]\n",
    "    return pd.to_datetime(fechas).date\n",
    "\n",
    "# Recorrer todos los archivos .txt de días faltantes\n",
    "faltantes_files = list(FALTANTES_DIR.glob(\"*.txt\"))\n",
    "\n",
    "resumen_resultados = []\n",
    "\n",
    "for file_path in faltantes_files:\n",
    "    estacion = file_path.stem.replace(\"dias_faltantes_\", \"\").replace(\"_\", \" \").upper()\n",
    "    dias_faltantes = leer_dias_faltantes(file_path)\n",
    "    \n",
    "    print(f\"\\n=== Estación: {estacion} ===\")\n",
    "    resultados_estacion = {\"Estación\": estacion, \"Total días faltantes\": len(dias_faltantes), \"Días completos\": 0, \"Días con NaN\": 0}\n",
    "    \n",
    "    for fecha in dias_faltantes:\n",
    "        subset_original = df_horario_completo[(df_horario_completo['NOMBRE'].str.upper() == estacion) & (df_horario_completo['FECHA'] == fecha)]\n",
    "        subset_imputado = df_interp[(df_interp['NOMBRE'].str.upper() == estacion) & (df_interp['FECHA'] == fecha)]\n",
    "        \n",
    "        if subset_imputado[variables_objetivo].isnull().any().any():\n",
    "            resultados_estacion[\"Días con NaN\"] += 1\n",
    "            print(f\"\\nFecha {fecha} aún con NaN\")\n",
    "        else:\n",
    "            resultados_estacion[\"Días completos\"] += 1\n",
    "            print(f\"\\nFecha {fecha} imputada correctamente\")\n",
    "        \n",
    "        # Comparar antes y después\n",
    "        if not subset_imputado.empty:\n",
    "            print(\"\\n--- Antes (Original con NaN) ---\")\n",
    "            print(subset_original[['FECHA_HORA', 'NOMBRE'] + variables_objetivo])\n",
    "            print(\"\\n--- Después (Imputado) ---\")\n",
    "            print(subset_imputado[['FECHA_HORA', 'NOMBRE'] + variables_objetivo])\n",
    "    \n",
    "    resumen_resultados.append(resultados_estacion)\n",
    "\n",
    "# Mostrar resumen final\n",
    "df_resumen = pd.DataFrame(resumen_resultados)\n",
    "print(\"\\nResumen de verificación de imputaciones por estación:\")\n",
    "print(df_resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a775e-65d6-4257-87bd-2ca94a7ec61b",
   "metadata": {},
   "source": [
    "# Verificación de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "505c7ad1-8fc5-4237-bb4f-73822d928246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron fechas faltantes después de la imputación.\n",
      "\n",
      "Ejemplo de fechas faltantes:\n",
      "Empty DataFrame\n",
      "Columns: [NOMBRE, FECHA]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame reducido solo con días únicos por estación\n",
    "df_fechas = df_interp[['FECHA', 'NOMBRE']].drop_duplicates()\n",
    "\n",
    "# Generar rango completo de fechas\n",
    "fechas_totales = pd.date_range(start=df_fechas['FECHA'].min(), end=df_fechas['FECHA'].max(), freq='D')\n",
    "\n",
    "# Estaciones\n",
    "estaciones = df_fechas['NOMBRE'].unique()\n",
    "# Crear todas las combinaciones posibles (fecha, estación)\n",
    "index_completo = pd.MultiIndex.from_product([fechas_totales, estaciones], names=['FECHA', 'NOMBRE'])\n",
    "\n",
    "# Reindexar\n",
    "df_check = df_fechas.set_index(['FECHA', 'NOMBRE']).reindex(index_completo).reset_index()\n",
    "\n",
    "# Verificar faltantes\n",
    "faltantes = df_check[df_check.isnull().any(axis=1)][['NOMBRE', 'FECHA']]\n",
    "\n",
    "# Exportar resultados\n",
    "if not faltantes.empty:\n",
    "    archivo_faltantes_final = PLATA_DIR / \"fechas_faltantes_post_imputacion.txt\"\n",
    "    faltantes.to_csv(archivo_faltantes_final, index=False, sep='\\t')\n",
    "    print(f\"Fechas faltantes exportadas a: {archivo_faltantes_final}\")\n",
    "else:\n",
    "    print(\"No se encontraron fechas faltantes después de la imputación.\")\n",
    "\n",
    "# Vista rápida\n",
    "print(\"\\nEjemplo de fechas faltantes:\")\n",
    "print(faltantes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa51e0-6e02-4cda-820c-d2c6f8b5c2eb",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "En este notebook hemos completado el proceso de **enriquecimiento de la Capa Plata**.\n",
    "\n",
    "Se garantiza:\n",
    "- **Datos horarios completos** por estación para el período de análisis.\n",
    "- **Tratamiento adecuado de valores faltantes**, aplicando imputaciones coherentes con el comportamiento histórico de cada estación.\n",
    "- Generación de un **dataset final imputado** que sirve como base para análisis avanzados (clustering, PCA, detección de eventos).\n",
    "\n",
    "Con esta preparación, los datos están listos para las tareas de **minería de datos y categorización**, que abordaremos en la clase siguiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

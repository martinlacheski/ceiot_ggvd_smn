{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Clase 3 ‚Äì Ingesta y Capa Bronce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a3d2d",
   "metadata": {},
   "source": [
    "En esta notebook se inicia la construcci√≥n del pipeline de datos meteorol√≥gicos, trabajando con los archivos crudos provistos por el SMN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## 1. Librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "573fb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n de paths y carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "069e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "for path in [BRONCE_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## 3. Lectura del archivo de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones cargadas: 117\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "archivo_estaciones = RAW_DIR / 'estaciones' / 'estaciones_smn.txt'\n",
    "\n",
    "# Leer todas las l√≠neas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_estaciones, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()[2:]\n",
    "\n",
    "# Expresi√≥n regular para extraer campos:\n",
    "pattern = re.compile(\n",
    "    r\"^(?P<nombre>.+?)\\s{2,}(?P<provincia>.+?)\\s{2,}(?P<lat_gr>-?\\d+)\\s+(?P<lat_min>\\d+)\\s+(?P<lon_gr>-?\\d+)\\s+(?P<lon_min>\\d+)\\s+(?P<altura_m>\\d+)\\s+(?P<numero>\\d+)\\s+(?P<numero_oaci>\\S+)\\s*$\"\n",
    ")\n",
    "\n",
    "# Extraer los datos\n",
    "data = []\n",
    "for line in lines:\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        data.append(match.groupdict())\n",
    "\n",
    "# Crear DataFrame\n",
    "df_estaciones = pd.DataFrame(data)\n",
    "\n",
    "# Conversi√≥n de tipos\n",
    "df_estaciones[['lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero']] = df_estaciones[[\n",
    "    'lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero'\n",
    "]].apply(pd.to_numeric)\n",
    "\n",
    "print(\"Estaciones cargadas:\", len(df_estaciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## 4. Selecci√≥n de estaciones de Misiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0fa485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>provincia</th>\n",
       "      <th>numero</th>\n",
       "      <th>numero_oaci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>BERNARDO DE IRIGOYEN AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87163</td>\n",
       "      <td>SATI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>IGUAZU AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87097</td>\n",
       "      <td>SARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>OBERA</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87187</td>\n",
       "      <td>SATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>POSADAS AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87178</td>\n",
       "      <td>SARP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nombre provincia  numero numero_oaci\n",
       "77  BERNARDO DE IRIGOYEN AERO  MISIONES   87163        SATI\n",
       "78                IGUAZU AERO  MISIONES   87097        SARI\n",
       "79                      OBERA  MISIONES   87187        SATO\n",
       "80               POSADAS AERO  MISIONES   87178        SARP"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misiones = df_estaciones[df_estaciones['provincia'].str.upper() == 'MISIONES']\n",
    "df_misiones[['nombre', 'provincia', 'numero', 'numero_oaci']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545f8b9",
   "metadata": {},
   "source": [
    "## 5. Lectura de un archivo horario de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c3af388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[HOA]  [¬∫C]   [%]  [hPa]  [gr] [km/hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01062024     0  14.2   82  1015.7   50   17   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01062024     1  14.3   80  1015.4  360    9   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01062024     2  14.1   86  1015.3  360    9   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01062024     3  14.1   87  1014.8  360    7   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE                                             \n",
       "0           [HOA]  [¬∫C]   [%]  [hPa]  [gr] [km/hr...                                                  \n",
       "1  01062024     0  14.2   82  1015.7   50   17   ...                                                  \n",
       "2  01062024     1  14.3   80  1015.4  360    9   ...                                                  \n",
       "3  01062024     2  14.1   86  1015.3  360    9   ...                                                  \n",
       "4  01062024     3  14.1   87  1014.8  360    7   ...                                                  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20240601.txt'\n",
    "df_dato = pd.read_csv(archivo_dato, sep=';', encoding='latin1')\n",
    "df_dato.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425531c",
   "metadata": {},
   "source": [
    "## 6. Limpieza b√°sica y detecci√≥n de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36cc4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reemplazados 0 valores de 9999.9 y 0 valores de -9999 por NaN.\n",
      "Valores faltantes por columna luego del reemplazo:\n",
      "FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE                                                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores a reemplazar antes de la limpieza\n",
    "cant_9999_9 = (df_dato == 9999.9).sum().sum()\n",
    "cant_neg9999 = (df_dato == -9999).sum().sum()\n",
    "\n",
    "# Reemplazar por NaN\n",
    "df_dato.replace({9999.9: np.nan, -9999: np.nan}, inplace=True)\n",
    "\n",
    "# Imprimir resumen\n",
    "print(f\"Reemplazados {cant_9999_9} valores de 9999.9 y {cant_neg9999} valores de -9999 por NaN.\")\n",
    "print(\"Valores faltantes por columna luego del reemplazo:\")\n",
    "print(df_dato.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03c2ef",
   "metadata": {},
   "source": [
    "## 7. Filtro por estaci√≥n de Misiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d97ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FECHA HORA TEMP HUM    PNM  DD FF       NOMBRE\n",
      "01062024    0 13.8  91 1019.6  90  7  IGUAZU AERO\n",
      "01062024    1 13.4  92 1019.5  90  7  IGUAZU AERO\n",
      "01062024    2 13.0  94 1019.0  90 11  IGUAZU AERO\n",
      "01062024    3 12.8  94 1018.3  90  9  IGUAZU AERO\n",
      "01062024    4 12.4  94 1018.3  90  7  IGUAZU AERO\n",
      "01062024    5 12.0  94 1018.7  50  4  IGUAZU AERO\n",
      "01062024    6 10.9  95 1019.1  70  4  IGUAZU AERO\n",
      "01062024    7 10.5  94 1020.5  90  6  IGUAZU AERO\n",
      "01062024    8 11.5  91 1021.3  90  4  IGUAZU AERO\n",
      "01062024    9 13.4  86 1021.4  90 17  IGUAZU AERO\n",
      "01062024   10 15.6  83 1021.6  90 13  IGUAZU AERO\n",
      "01062024   11 18.0  75 1021.4  90 15  IGUAZU AERO\n",
      "01062024   12 19.7  68 1020.7  90 17  IGUAZU AERO\n",
      "01062024   13 20.4  68 1020.0 110 11  IGUAZU AERO\n",
      "01062024   14 21.5  65 1019.1 110 13  IGUAZU AERO\n",
      "01062024   15 22.8  64 1018.3  90  9  IGUAZU AERO\n",
      "01062024   16 22.6  62 1017.9  90  9  IGUAZU AERO\n",
      "01062024   17 22.4  68 1017.8  90  9  IGUAZU AERO\n",
      "01062024   18 19.0  81 1018.1  90  9  IGUAZU AERO\n",
      "01062024   19 18.4  84 1018.3  90  6  IGUAZU AERO\n",
      "01062024   20 17.5  85 1018.5  90  4  IGUAZU AERO\n",
      "01062024   21 17.6  81 1018.5  90  7  IGUAZU AERO\n",
      "01062024   22 17.0  81 1018.1  90  6  IGUAZU AERO\n",
      "01062024   23 16.0  87 1018.1  90  7  IGUAZU AERO\n",
      "01062024    9 16.8  72 1020.4 320  4        OBERA\n",
      "01062024   15 22.8  84 1018.4  50  4        OBERA\n",
      "01062024   21 16.8  63 1017.6  50  4        OBERA\n",
      "01062024    0 16.0  85 1017.4  50  6 POSADAS AERO\n",
      "01062024    1 15.5  86 1016.9  70  7 POSADAS AERO\n",
      "01062024    2 15.5  82 1016.5  50  7 POSADAS AERO\n",
      "01062024    3 15.3  82 1016.2  50  7 POSADAS AERO\n",
      "01062024    4 14.6  86 1016.0  90  7 POSADAS AERO\n",
      "01062024    5 14.6  86 1016.3  50  7 POSADAS AERO\n",
      "01062024    6 14.4  82 1016.3  50  7 POSADAS AERO\n",
      "01062024    7 14.0  83 1017.4  50  6 POSADAS AERO\n",
      "01062024    8 13.8  86 1018.1  90  6 POSADAS AERO\n",
      "01062024    9 15.4  79 1018.4  70 11 POSADAS AERO\n",
      "01062024   10 17.6  71 1018.6  50 13 POSADAS AERO\n",
      "01062024   11 19.4  65 1018.8  20 13 POSADAS AERO\n",
      "01062024   12 21.0  64 1018.5  20 13 POSADAS AERO\n",
      "01062024   13 22.6  62 1017.6  20  7 POSADAS AERO\n",
      "01062024   14 24.4  55 1016.6  20 11 POSADAS AERO\n",
      "01062024   15 24.8  54 1016.0  50  9 POSADAS AERO\n",
      "01062024   16 24.4  56 1015.5  20 13 POSADAS AERO\n",
      "01062024   17 24.2  57 1015.3  20 11 POSADAS AERO\n",
      "01062024   18 23.8  59 1015.4  20  9 POSADAS AERO\n",
      "01062024   19 20.2  77 1015.9  70  7 POSADAS AERO\n",
      "01062024   20 19.4  79 1016.3  90  9 POSADAS AERO\n",
      "01062024   21 18.9  81 1016.5  70  9 POSADAS AERO\n",
      "01062024   22 18.7  80 1016.5  70  9 POSADAS AERO\n",
      "01062024   23 18.3  80 1016.6  50 11 POSADAS AERO\n"
     ]
    }
   ],
   "source": [
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20240601.txt'\n",
    "\n",
    "# Leer todas las l√≠neas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_dato, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Detectar columnas separadas por m√∫ltiples espacios\n",
    "columnas = re.split(r\"\\s{2,}\", lines[0].strip())\n",
    "\n",
    "# Leer datos\n",
    "data = [\n",
    "    re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "    for line in lines[1:]\n",
    "    if len(line.strip()) > 0 and not line.isspace()\n",
    "]\n",
    "\n",
    "df_dato = pd.DataFrame(data, columns=columnas)\n",
    "\n",
    "# Filtrar por estaciones de Misiones\n",
    "df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "nombres_misiones = df_misiones[\"nombre\"].str.strip().unique()\n",
    "df_misiones_dia = df_dato[df_dato[\"NOMBRE\"].isin(nombres_misiones)]\n",
    "#print(df_misiones_dia.head())\n",
    "\n",
    "# Mostrar todos los resultados (sin limitar con .head())\n",
    "print(df_misiones_dia.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63370d18",
   "metadata": {},
   "source": [
    "## 8. Exportaci√≥n de archivos filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f344ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: 20240601_bernardo_de_irigoyen_aero.csv y 20240601_bernardo_de_irigoyen_aero.parquet\n",
      "Exportado: 20240601_iguazu_aero.csv y 20240601_iguazu_aero.parquet\n",
      "Exportado: 20240601_obera.csv y 20240601_obera.parquet\n",
      "Exportado: 20240601_posadas_aero.csv y 20240601_posadas_aero.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta de salida si no existe\n",
    "BRONCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Definir la fecha (puede venir del nombre del archivo)\n",
    "fecha = \"20240601\"  # o extraela din√°micamente si lo prefer√≠s\n",
    "\n",
    "# Iterar por cada estaci√≥n de Misiones\n",
    "for nombre in nombres_misiones:\n",
    "    nombre_clean = nombre.lower().replace(' ', '_')\n",
    "    \n",
    "    # Filtrar las filas de esa estaci√≥n\n",
    "    df_estacion = df_misiones_dia[df_misiones_dia[\"NOMBRE\"] == nombre]\n",
    "    \n",
    "    # Definir archivos de salida con fecha al inicio\n",
    "    salida_csv = BRONCE_DIR / f'{fecha}_{nombre_clean}.csv'\n",
    "    salida_parquet = BRONCE_DIR / f'{fecha}_{nombre_clean}.parquet'\n",
    "    \n",
    "    # Exportar\n",
    "    df_estacion.to_csv(salida_csv, index=False)\n",
    "    df_estacion.to_parquet(salida_parquet, index=False)\n",
    "    \n",
    "    print(f\"Exportado: {salida_csv.name} y {salida_parquet.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53b561",
   "metadata": {},
   "source": [
    "## Pr√≥ximos pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7c349",
   "metadata": {},
   "source": [
    "- Extender este proceso a m√°s d√≠as o meses.\n",
    "- Organizar las salidas por carpeta `/bronce/{estacion}/{a√±o}/`.\n",
    "- Documentar el diccionario de variables en `metadata/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832851a",
   "metadata": {},
   "source": [
    "### üîü Paso 9 ‚Äì Procesamiento por estaci√≥n y por fecha (con limpieza y reporte resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5af8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Proceso completado.\n",
      "D√≠as procesados: 391\n",
      "Errores al procesar archivos: 391\n",
      "Valores reemplazados: 0 de 9999.9 y 0 de -9999\n",
      "Total de valores nulos luego de limpieza: 260790\n"
     ]
    }
   ],
   "source": [
    "# Buscar todos los archivos datohorario disponibles\n",
    "archivos_datos = sorted(glob(str(RAW_DIR / \"datohorario\" / \"datohorario*.txt\")))\n",
    "\n",
    "errores_globales = 0\n",
    "nulos_total = 0\n",
    "reemplazados_9999_9 = 0\n",
    "reemplazados_neg9999 = 0\n",
    "detalle_nulos = []\n",
    "\n",
    "for archivo in archivos_datos:\n",
    "    try:\n",
    "        with open(archivo, encoding=\"latin1\") as f:\n",
    "            raw_lines = f.readlines()\n",
    "\n",
    "        header = raw_lines[0].strip()\n",
    "        columnas = re.split(r\"\\s{2,}\", header)\n",
    "\n",
    "        data = [\n",
    "            re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "            for line in raw_lines[1:]\n",
    "            if len(line.strip()) > 0 and not line.isspace()\n",
    "        ]\n",
    "\n",
    "        df_dato = pd.DataFrame(data, columns=columnas)\n",
    "        df_dato.columns = df_dato.columns.str.strip()\n",
    "        df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "        # Convertir columnas num√©ricas si es posible\n",
    "        for col in df_dato.columns:\n",
    "            try:\n",
    "                df_dato[col] = pd.to_numeric(df_dato[col])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Conteo previo de valores a reemplazar\n",
    "        cant_9999_9 = (df_dato == 9999.9).sum().sum()\n",
    "        cant_neg9999 = (df_dato == -9999).sum().sum()\n",
    "\n",
    "        reemplazados_9999_9 += cant_9999_9\n",
    "        reemplazados_neg9999 += cant_neg9999\n",
    "\n",
    "        # Reemplazo\n",
    "        df_dato.replace({9999.9: np.nan, -9999: np.nan}, inplace=True)\n",
    "\n",
    "        # Contar nulos\n",
    "        nulos_total += df_dato.isna().sum().sum()\n",
    "\n",
    "        # Filtrar por estaciones de Misiones\n",
    "        df_misiones = df_dato[df_dato[\"NOMBRE\"].isin(nombres_misiones)]\n",
    "\n",
    "        # Obtener fecha\n",
    "        fecha = Path(archivo).stem.replace(\"datohorario\", \"\")\n",
    "\n",
    "        # Guardar archivos por estaci√≥n + generar detalle\n",
    "        for nombre in nombres_misiones:\n",
    "            nombre_clean = nombre.lower().replace(\" \", \"_\")\n",
    "            df_estacion = df_misiones[df_misiones[\"NOMBRE\"] == nombre]\n",
    "\n",
    "            if not df_estacion.empty:\n",
    "                path_estacion = BRONCE_DIR / nombre_clean\n",
    "                path_estacion.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                df_estacion.to_parquet(path_estacion / f\"{fecha}.parquet\", index=False)\n",
    "                df_estacion.to_csv(path_estacion / f\"{fecha}.csv\", index=False)\n",
    "\n",
    "                # Registro de nulos por estaci√≥n\n",
    "                nulos_por_col = df_estacion.isna().sum()\n",
    "                detalle_nulos.append({\n",
    "                    \"archivo\": Path(archivo).name,\n",
    "                    \"fecha\": fecha,\n",
    "                    \"estacion\": nombre,\n",
    "                    \"nulos_totales\": int(nulos_por_col.sum()),\n",
    "                    \"nulos_por_columna\": json.dumps(nulos_por_col[nulos_por_col > 0].to_dict())\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        errores_globales += 1\n",
    "        continue\n",
    "\n",
    "# Reporte final\n",
    "print(\"‚úÖ Proceso completado.\")\n",
    "print(f\"D√≠as procesados: {len(archivos_datos)}\")\n",
    "print(f\"Errores al procesar archivos: {errores_globales}\")\n",
    "print(f\"Valores reemplazados: {reemplazados_9999_9} de 9999.9 y {reemplazados_neg9999} de -9999\")\n",
    "print(f\"Total de valores nulos luego de limpieza: {nulos_total}\")\n",
    "\n",
    "# Guardar resumen general\n",
    "reporte = {\n",
    "    \"dias_procesados\": [len(archivos_datos)],\n",
    "    \"errores\": [errores_globales],\n",
    "    \"reemplazados_9999_9\": [reemplazados_9999_9],\n",
    "    \"reemplazados_-9999\": [reemplazados_neg9999],\n",
    "    \"valores_nulos_totales\": [nulos_total],\n",
    "}\n",
    "df_reporte = pd.DataFrame(reporte)\n",
    "df_reporte.to_csv(BRONCE_DIR / \"reporte_resumen.csv\", index=False)\n",
    "\n",
    "# Guardar detalle de nulos por archivo y estaci√≥n\n",
    "df_detalle = pd.DataFrame(detalle_nulos)\n",
    "df_detalle.to_csv(BRONCE_DIR / \"reporte_nulos_detalle.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

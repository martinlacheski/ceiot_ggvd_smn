# GGVD SMN â€“ GestiÃ³n de Grandes VolÃºmenes de Datos (Servicio MetereolÃ³gico Nacional - Argentina)

Este proyecto implementa un **pipeline de datos por capas (Bronce â†’ Plata â†’ Oro)** para procesar informaciÃ³n meteorolÃ³gica proveniente del **Servicio MeteorolÃ³gico Nacional (SMN)** de Argentina.  
Incluye **procesamiento por lotes** y **procesamiento en tiempo real**, con almacenamiento en **TimescaleDB** y visualizaciÃ³n en **Grafana**, todo orquestado mediante **Docker Compose**.

---

## ğŸš€ CaracterÃ­sticas principales

- **Pipeline de datos por capas**:
  - **Bronce**: ingesta de datos crudos.
  - **Plata**: limpieza, estandarizaciÃ³n y enriquecimiento.
  - **Oro**: datasets analÃ­ticos listos para modelado o visualizaciÃ³n.
- **Procesamiento en dos modos**:
  - **Por lotes (batch)**: procesa grandes volÃºmenes de datos histÃ³ricos, genera `.csv` listos sin guardar en la base de datos.
  - **En tiempo real (streaming)**: inserta directamente en TimescaleDB los datos tal como llegan de las estaciones meteorolÃ³gicas.
- **Watchers automÃ¡ticos** que monitorean directorios y ejecutan pipelines.
- **Base de datos de series temporales**: PostgreSQL + TimescaleDB.
- **pgAdmin** para administraciÃ³n de la base de datos.
- **Grafana** para visualizaciÃ³n y monitoreo en tiempo real.
- **Entorno reproducible** con Docker Compose.

---

## ğŸ—‚ï¸ Estructura del proyecto

```
ceiot_ggvd_smn/
â”œâ”€ api/                   # Endpoints y lÃ³gica de ingesta en tiempo real
â”œâ”€ data/
â”‚  â”œâ”€ raw/                # Datos crudos descargados
â”‚  â”œâ”€ diccionario/        # Diccionario de variables y metadatos del dataset
â”‚  â”œâ”€ faltantes/          # Registros o variables con datos faltantes detectados en la limpieza
â”‚  â”œâ”€ mineria/            # Resultados y salidas de procesos de minerÃ­a de datos
â”‚  â”œâ”€ clasificacion/      # Resultados y modelos generados en la etapa de clasificaciÃ³n
â”‚  â”œâ”€ bronce/             # Datos procesados por ingesta (batch)
â”‚  â”œâ”€ plata/              # Datos limpios y estandarizados
â”‚  â””â”€ oro/                # Datasets finales para anÃ¡lisis/modelos
â”œâ”€ db/                    # Scripts de inicializaciÃ³n de la base de datos
â”œâ”€ grafana/               # ConfiguraciÃ³n y dashboards de Grafana
â”œâ”€ notebooks/             # Procesamiento manual y visualizaciones
â”œâ”€ pipeline/              # Pipelines Bronce â†’ Plata â†’ Oro
â”œâ”€ watchers/              # Scripts que monitorean y ejecutan pipelines
â”œâ”€ docker-compose.yml     # OrquestaciÃ³n de servicios
â”œâ”€ Dockerfile             # Imagen para entorno de notebooks/pipelines
â”œâ”€ requirements.txt       # Dependencias Python
â”œâ”€ env.template           # Variables de entorno base
â”œâ”€ LICENSE                # Licencia del proyecto
â””â”€ README.md              # Este archivo
```

---

## ğŸ”§ Requisitos

- **Docker** y **Docker Compose** instalados.

---

## â–¶ï¸ EjecuciÃ³n con Docker Compose

### 1) Levantar todos los servicios
```bash
docker compose up --build
```

Esto levantarÃ¡:

- **Jupyter**: entorno Jupyter con notebooks que ejecutan el pipeline y herramientas de anÃ¡lisis.
- **db**: PostgreSQL con extensiÃ³n TimescaleDB.
- **pgAdmin**: interfaz de administraciÃ³n de base de datos.
- **grafana**: visualizaciÃ³n y dashboards.
- **watchers**: monitorean y procesan datos automÃ¡ticamente.

---

### 2) Acceso a servicios

| Servicio       | URL                               | Usuario / Pass (por defecto)      |
|----------------|-----------------------------------|------------------------------------|
| Jupyter Lab    | [http://localhost:8888](http://localhost:8888) | Sin Usuario ni Pass (uso local)           |
| pgAdmin        | [http://localhost:5050](http://localhost:5050) | `admin@admin.com` / `admin`        |
| Grafana        | [http://localhost:3000](http://localhost:3000) | `admin` / `admin`                   |
| PostgreSQL     | `localhost:5432`                  | `postgres` / `postgres`            |

---

## ğŸ“’ Flujo de trabajo

### **Procesamiento por lotes (Batch)**
1. **Descarga de datos histÃ³ricos**  
   Colocar archivos crudos del SMN en `data/raw/datohorario`.
2. **EjecuciÃ³n de pipelines**  
   Los watchers o notebooks ejecutan:
   - `pipeline_01_ingest_to_bronce.py`
   - `pipeline_02_bronce_to_plata.py`
   - `pipeline_03_plata_to_oro.py`
3. **Salida**  
   Se generan `.csv` en las carpetas Bronce, Plata y Oro.  
   **No se insertan en TimescaleDB**.

---

### **Procesamiento en tiempo real (Streaming)**
1. **RecepciÃ³n de datos de estaciones meteorolÃ³gicas**  
   Simulados o reales, recibidos mediante endpoints o scripts.
2. **InserciÃ³n directa en TimescaleDB**  
   Los datos se almacenan tal cual llegan, con mÃ­nima transformaciÃ³n.
3. **VisualizaciÃ³n inmediata**  
   Grafana muestra los datos en dashboards configurados en tiempo real.

---

## ğŸ§© Watchers

- Monitorean directorios de entrada (`data/raw/`).
- Detectan nuevos archivos.
- Ejecutan el pipeline correspondiente.
- Registran en `procesados.csv` para evitar reprocesos.

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo **Licencia MIT**.  
Ver [LICENSE](LICENSE) para mÃ¡s detalles.
